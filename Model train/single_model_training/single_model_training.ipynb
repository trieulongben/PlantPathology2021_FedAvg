{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "import multiprocessing as mp\n",
    "from re import T\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "#from model import net\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torchvision import datasets,transforms\n",
    "import random\n",
    "from torch import optim,ceil\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "import multiprocessing as mp\n",
    "from re import T\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class plantdisease(Dataset):\n",
    "    def __init__(self, df,\n",
    "                  img_dir='data/oneFolder'\n",
    "                 , isTest=False):\n",
    "        self.img_labels=df\n",
    "        self.img_dir='../../Data/DataResized512/'\n",
    "       # self.train, self.test = train_test_split(self.img_labels, test_size=0.05)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels['image'][idx])\n",
    "\n",
    "            image = (read_image(img_path).float())\n",
    "            self.transform=transforms.Compose([transforms.Resize((342,512)),\n",
    "        transforms.Normalize((124.4455, 159.9584, 104.1832), (47.1528, 41.4626, 49.2424))])\n",
    "            image = self.transform(image)\n",
    "            label = self.img_labels['labels'][idx]\n",
    "            label=np.fromstring(label[1:-1], dtype=np.int,sep=',')\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_size(size) -> str:\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\ttorch.cuda.empty_cache()\n",
    "\tprint(\"Total size:\", total_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "\n",
    "    dump_tensors()\n",
    "def save_model(model):\n",
    "    file_name='testingmodel.h5'\n",
    "    torch.save(model.state_dict(), file_name)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confusion_matrixCal(target,pred):\n",
    "  matrix=0\n",
    "  for i in range(0,target.shape[0]):\n",
    "    matrix+=confusion_matrix(target[i], pred[i],labels=[1, 0])\n",
    "  return matrix\n",
    "\n",
    "#Test train function\n",
    "\n",
    "config = {\n",
    "        \"lr\": 0.0001,\n",
    "        \"batch_size\": 6\n",
    "        ,\"epoch\":20\n",
    "    }\n",
    "def client_trainGPU(config,run):\n",
    "  \n",
    "  # Wandb\n",
    "  loss_function=torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "  wandb.watch(model, loss_function, log=\"all\", log_freq=10)\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  optimizer =optim.Adam(model.parameters(),lr=config[\"lr\"],weight_decay=9e-05)\n",
    "\n",
    "  train_dataloader=DataLoader(train_data,batch_size=int(config[\"batch_size\"]))\n",
    "  test_dataloader=DataLoader(test_data,batch_size=int(config[\"batch_size\"]))\n",
    "\n",
    "\n",
    "\n",
    "  for epoc in range(config['epoch']):\n",
    "      model.to(device)\n",
    "\n",
    "      train_loss = 0.0\n",
    "      confusionMatrix=0\n",
    "      train_step=0\n",
    "      print('start Epoch ',epoc)\n",
    "      for _, datas in enumerate(((train_dataloader)),0):\n",
    "          data, target=datas\n",
    "          data,target=data.to(device),target.to(device)\n",
    "          \n",
    "          \n",
    "          output = model(data)\n",
    "\n",
    "          loss = loss_function(output, target.float())\n",
    "\n",
    "          train_loss += loss.item()\n",
    "          train_step+=1\n",
    "\n",
    "\n",
    "          ouput=torch.sigmoid(output)\n",
    "          predicted = torch.round(ouput)\n",
    "          target=target.cpu()\n",
    "          data=data.cpu()\n",
    "          predicted=predicted.cpu()\n",
    "          confusionMatrix+=confusion_matrixCal(target,predicted)\n",
    "          optimizer.zero_grad(set_to_none=True)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "      print('Client ID ',  ', epoch ',\n",
    "        epoc, ': ', train_loss / train_step)\n",
    "\n",
    "      #Evaluation\n",
    "\n",
    "      ######\n",
    "      confusionMatrix_test=0\n",
    "      test_loss = 0.0\n",
    "      test_step=0\n",
    "\n",
    "      best_eval_accuracy=0\n",
    "\n",
    "      model.cpu()\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        for _, datas in enumerate(((test_dataloader)),0):\n",
    "            data, target=datas\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            loss =loss_function(output, target.float())\n",
    "            ouput=torch.sigmoid(output)\n",
    "            predicted = np.round(ouput)\n",
    "            test_loss += loss.item()\n",
    "            test_step+=1\n",
    "\n",
    "            confusionMatrix_test+=confusion_matrixCal(target,predicted)\n",
    "      \n",
    "      print('test_loss {}'.format(test_loss/test_step))\n",
    "      train_loss=train_loss / train_step\n",
    "      test_loss=test_loss/test_step\n",
    "\n",
    "      TP_test=confusionMatrix_test[0][0]\n",
    "      FP_test=confusionMatrix_test[0][1]\n",
    "      FN_test=confusionMatrix_test[1][0]\n",
    "      TN_test=confusionMatrix_test[1][1]\n",
    "      accuracy_test=(TP_test+TN_test)/(FP_test+FN_test+TP_test+TN_test)\n",
    "      recal_test=TP_test/(TP_test+FN_test)\n",
    "      precision_test=TP_test/(TP_test+FP_test)\n",
    "      negativePredictiveValue_test=TN_test/(TN_test+FN_test)\n",
    "      missRate_test=FN_test/(TP_test+FN_test)\n",
    "      fallOut_test=FP_test/(TN_test+FP_test)\n",
    "      f1_test=(2*precision_test*recal_test)/(precision_test+recal_test)\n",
    "\n",
    "\n",
    "      TP_train=confusionMatrix[0][0]\n",
    "      FP_train=confusionMatrix[0][1]\n",
    "      FN_train=confusionMatrix[1][0]\n",
    "      TN_train=confusionMatrix[1][1]\n",
    "      accuracy_train=(TP_train+TN_train)/(FP_train+FN_train+TP_train+TN_train)\n",
    "      recal_train=TP_train/(TP_train+FN_train)\n",
    "      precision_train=TP_train/(TP_train+FP_train)\n",
    "      negativePredictiveValue_train=TN_train/(TN_train+FN_train)\n",
    "      missRate_train=FN_train/(TP_train+FN_train)\n",
    "      fallOut_train=FP_train/(TN_train+FP_train)\n",
    "      f1_train=(2*precision_train*recal_train)/(precision_train+recal_train)\n",
    "      if best_eval_accuracy<accuracy_test:\n",
    "        best_eval_accuracy=accuracy_test\n",
    "        model_log = wandb.Artifact('best_eval_accuracy', type='model')\n",
    "        try:\n",
    "          model_log.add_file(save_model(model))\n",
    "          run.log_artifact(model_log)\n",
    "          print('model saved, best accuracy: {}'.format(best_eval_accuracy))\n",
    "        except:\n",
    "          print('save model failed')\n",
    "\n",
    "      wandb.log({\n",
    "            'epoc': epoc, \n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': test_loss,\n",
    "\n",
    "            \n",
    "            'TP_test':TP_test,\n",
    "            'FP_test':FP_test,\n",
    "            'FN_test':FN_test,\n",
    "            'TN_test':TN_test,\n",
    "            'accuracy_test':accuracy_test,\n",
    "            'recal_test':recal_test,\n",
    "            'precision_test':precision_test,\n",
    "            'negativePredictiveValue_test':negativePredictiveValue_test,\n",
    "            'f1_test':f1_test,\n",
    "\n",
    "\n",
    "            'TP':TP_train,\n",
    "            'FP':FP_train,\n",
    "            'FN':FN_train,\n",
    "            'TN':TN_train,\n",
    "            'accuracy_train':accuracy_train,\n",
    "            'recal_train':recal_train,\n",
    "            'precision_train':precision_train,\n",
    "            'negativePredictiveValue_train':negativePredictiveValue_train,\n",
    "            'f1_train':f1_train,\n",
    "          })\n",
    "\n",
    "  free_gpu_cache()\n",
    "  print(\"Finished Training\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2qulrsez) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88eb6c5681154d688b41216ff3c85080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.108599…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">morning-voice-8</strong>: <a href=\"https://wandb.ai/makkuror/Thesis/runs/2qulrsez\" target=\"_blank\">https://wandb.ai/makkuror/Thesis/runs/2qulrsez</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221203_223903-2qulrsez\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2qulrsez). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b21acc3b12495f8fbc8c89099aa9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\single_model_training\\wandb\\run-20221203_223939-3o93qxuc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/Thesis/runs/3o93qxuc\" target=\"_blank\">neat-snowflake-9</a></strong> to <a href=\"https://wandb.ai/makkuror/Thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  6.428118379088119\n",
      "accuracy 0.663625\n",
      "test_loss 0.11627152686317761\n",
      "accuracy 0.8174603174603174\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  4.212064170918893\n",
      "accuracy 0.794\n",
      "test_loss 0.13520628160664014\n",
      "accuracy 0.7867063492063492\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  3.1891820009914227\n",
      "accuracy 0.84\n",
      "test_loss 0.13134153672153986\n",
      "accuracy 0.8125\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  2.7146718773874454\n",
      "accuracy 0.859\n",
      "test_loss 0.14114743973764163\n",
      "accuracy 0.8154761904761905\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  2.4094277261465322\n",
      "accuracy 0.874125\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = '831281456cbf2d04f75207adc2e9811dc4fd32cf'\n",
    "projName='single_model_training1'\n",
    "import wandb\n",
    "def main():\n",
    "\n",
    "    run = wandb.init()\n",
    "    \n",
    "    # note that we define values from `wandb.config` instead \n",
    "    # of defining hard values\n",
    "\n",
    "    config = {\n",
    "        \"lr\": 0.00006824,\n",
    "        \"batch_size\":16,\n",
    "        \"epoch\":20\n",
    "    }\n",
    "    import warnings \n",
    "    warnings.filterwarnings('ignore')\n",
    "    a=client_trainGPU(config,run)\n",
    "\n",
    "    run.finish()\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear Memory GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    }
   ],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Thesis\\Model train\\single_model_training\\single_model_training.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/single_model_training/single_model_training.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,target\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/single_model_training/single_model_training.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m        \u001b[39mprint\u001b[39m(accuracy_score(target[i], pred[i]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/single_model_training/single_model_training.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m f1_score(a,b)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "cf_matrix=0\n",
    "\n",
    "def confusion_matrix(target,pred):\n",
    "    for i in range(0,target.shape[0]):\n",
    "        cf_matrix+=confusion_matrix(target[i], pred[i])\n",
    "def f1_score(target,pred):\n",
    "    for i in range(0,target.shape[0]):\n",
    "       print(accuracy_score(target[i], pred[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorchGPUI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8b858f47e475f096c0bf0df9132e4b2b12ebb02cb87303e1af43904bc641e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
