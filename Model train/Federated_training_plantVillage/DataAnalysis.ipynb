{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "import multiprocessing as mp\n",
    "from re import T\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "#from model import net\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torchvision import datasets,transforms\n",
    "import random\n",
    "from torch import optim,ceil\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class plantVillage(Dataset):\n",
    "    def __init__(self, df,\n",
    "                  img_dir='data/oneFolder'\n",
    "                 , isTest=False):\n",
    "        self.img_labels=df\n",
    "        self.img_dir='../../Data/PlantVillage/PlantVillage-Dataset-master/All/resized512/'\n",
    "       # self.train, self.test = train_test_split(self.img_labels, test_size=0.05)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels['image'][idx])\n",
    "\n",
    "            image = (read_image(img_path).float())\n",
    "            self.transform=transforms.Compose([transforms.Resize((342,512)),\n",
    "        transforms.Normalize((124.4455, 159.9584, 104.1832), (47.1528, 41.4626, 49.2424))])\n",
    "            image = self.transform(image)\n",
    "            label = self.img_labels['disease'][idx]\n",
    "            label=np.fromstring(label[1:-1], dtype=np.int,sep=',')\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./plantVillage.csv')\n",
    "df=df.drop('Unnamed: 0',axis=1)\n",
    "dataset=plantVillage(df=df)\n",
    "loader=DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nonom\\AppData\\Local\\Temp\\ipykernel_17796\\161376172.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label=np.fromstring(label[1:-1], dtype=np.int,sep=',')\n",
      "C:\\Users\\nonom\\AppData\\Local\\Temp\\ipykernel_17796\\161376172.py:23: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  label=np.fromstring(label[1:-1], dtype=np.int,sep=',')\n"
     ]
    }
   ],
   "source": [
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through imagesworkbench.action.openSettings\n",
    "for inputs in (loader):\n",
    "    psum    += inputs[0].sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs[0] ** 2).sum(axis = [0, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 167])\n",
      "torch.Size([3, 256, 235])\n",
      "torch.Size([3, 256, 233])\n",
      "torch.Size([3, 256, 162])\n"
     ]
    }
   ],
   "source": [
    "#There are images not in (256,256), lets count these\n",
    "dir='../../Data/PlantVillage/PlantVillage-Dataset-master/All/resized512/'\n",
    "for filename in os.listdir(dir):\n",
    "    temp=read_image(dir+filename)\n",
    "    if(str(temp.shape)!='torch.Size([3, 256, 256])'):\n",
    "        print(temp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21352611840\n",
      "21352920576\n",
      "mean: tensor([-0.7898, -1.4373, -0.6051])\n",
      "std:  tensor([1.3209, 1.5867, 1.1863])\n"
     ]
    }
   ],
   "source": [
    "# pixel count\n",
    "count256=4\n",
    "\n",
    "count = (len(dataset)-count256) * 256 * 256*3\n",
    "print(count)\n",
    "count+=256*167*3\n",
    "count+=256*235*3\n",
    "print(count)\n",
    "count+=256*233*3\n",
    "count+=256*162*3\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.1061, 13.7505,  5.3205])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(psum_sq / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.6143, 18.5933,  3.2956])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_mean)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4918, -4.8429,  2.0249])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean: tensor([125.1284, 160.8532, 104.8010])\n",
    "std:  tensor([46.3414, 39.7286, 48.7497])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorchGPUI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8b858f47e475f096c0bf0df9132e4b2b12ebb02cb87303e1af43904bc641e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
