{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "import multiprocessing as mp\n",
    "from re import T\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "#from model import net\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torchvision import datasets,transforms\n",
    "import random\n",
    "from torch import optim,ceil\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class plantVillage(Dataset):\n",
    "    def __init__(self, df,\n",
    "                  img_dir='data/oneFolder'\n",
    "                 , isTest=False):\n",
    "        self.img_labels=df\n",
    "        self.img_dir='../../Data/PlantVillage/PlantVillage-Dataset-master/All/resized512/'\n",
    "       # self.train, self.test = train_test_split(self.img_labels, test_size=0.05)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels['image'][idx])\n",
    "\n",
    "            image = (read_image(img_path).float())\n",
    "            self.transform=transforms.Compose([transforms.Resize((256,256)),\n",
    "        transforms.Normalize((-0.7898, -1.4373, -0.6051), (1.3209, 1.5867, 1.1863))])\n",
    "            image = self.transform(image)\n",
    "            label = self.img_labels['disease'][idx]\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./plantVillage.csv')\n",
    "df: DataFrame=df.drop('Unnamed: 0',axis=1)\n",
    "train,valid_test=train_test_split(df,test_size=0.2)\n",
    "valid,test=train_test_split(valid_test,test_size=0.5)\n",
    "\n",
    "train_data=plantVillage(df=train.reset_index())\n",
    "test_data=plantVillage(df=test.reset_index())\n",
    "valid_data=plantVillage(df=valid.reset_index())\n",
    "\n",
    "model=models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1]=(torch.nn.Linear(in_features=1280, out_features=21, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class Client():\n",
    "    def __init__(self,id,dataset,model,config) -> object:\n",
    "        self.id=id\n",
    "        self.dataset=dataset\n",
    "        self.model=model\n",
    "        self.criterion=torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.config=config\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "    def __str__(self) -> str:\n",
    "        print('Client ID: {}', self.id)\n",
    "        \n",
    "    def get_config(self):\n",
    "        print(self.config)\n",
    "        return self.config\n",
    "    \n",
    "    def update_model_params(self,params):\n",
    "        self.model.load_state_dict(params)\n",
    "\n",
    "    def metric(self,pred,label):\n",
    "        metric=MulticlassAccuracy(num_classes=21)\n",
    "        \n",
    "        return metric(pred,label).item()\n",
    "\n",
    "    def wandb_log(self,log={}):\n",
    "        try:\n",
    "            wandb.log(log)\n",
    "        except:\n",
    "            print('Wandb logging error {}', self.id)        \n",
    "    \n",
    "    def train_gpu(self,round):\n",
    "        optimizer=optim.Adam(self.model.parameters(),lr=self.config['learning_rate'],weight_decay=self.config['weight_decay'])\n",
    "        dataloader=torch.utils.data.DataLoader(self.dataset,\n",
    "                                         batch_size=int(self.config['batch_size']),\n",
    "                                         shuffle=True)\n",
    "\n",
    "        train_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model.to(train_device)\n",
    "\n",
    "        print('Client {} start Training'.format(self.id))\n",
    "\n",
    "        run=wandb.init(group=\"federated_round: \"+str(round), job_type=\"Client ID: \"+str(self.id), project=PROJNAME)\n",
    "        \n",
    "        for epoc in (range(self.config['epoch'])):\n",
    "            epoch_loss=0.0\n",
    "            step=0\n",
    "            epoc_accuracy=[]\n",
    "            \n",
    "            for x,y in iter(dataloader):\n",
    "                x,y=x.to(train_device),y.to(train_device)\n",
    "                output=self.model(x)\n",
    "\n",
    "                loss=self.criterion(pred,y)\n",
    "\n",
    "                x,y=x.cpu(),y.cpu()\n",
    "                output=output.cpu().detach()\n",
    "                epoch_loss+=loss.item()\n",
    "                step+=1\n",
    "                \n",
    "                pred=output.argmax(dim=1,keepdim=True).T[0]\n",
    "                epoc_accuracy.append(self.metric(pred,y))\n",
    "                \n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            accuracy=np.mean(epoc_accuracy)\n",
    "            print('Epoch : {} , loss: {}, accuracy: {}'.format(epoc,(epoch_loss/step),accuracy))\n",
    "\n",
    "            self.wandb_log({\n",
    "                            'epoc':epoc,\n",
    "                            'loss':(epoch_loss/step),\n",
    "                            'accuracy':accuracy\n",
    "                            })\n",
    "        self.model=self.model.cpu()\n",
    "        \n",
    "        run.finish()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "class Server():\n",
    "    def __init__(self,model=models.mobilenet_v2(pretrained=True),dataset=None,eval_dataset=None,config={}):\n",
    "        self.client_list=[]\n",
    "        self.model= model\n",
    "        self.model.classifier[1]=(torch.nn.Linear(in_features=1280, out_features=21, bias=True))\n",
    "        \n",
    "        self.dataset=dataset\n",
    "        self.eval_dataset=eval_dataset\n",
    "        self.round_dices=[]\n",
    "\n",
    "        self.best_accuracy=0.0\n",
    "        \n",
    "        self.config=config\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.client_list)\n",
    "\n",
    "    def get_config(self):\n",
    "        print(self.config)\n",
    "        return self.config\n",
    "\n",
    "    def split_dataset_1label(self):\n",
    "        list_dataset=np.array_split(self.dataset,self.config['server']['num_client'])\n",
    "        list_dataset=map(lambda df:  plantVillage(df.reset_index(drop=True)),list_dataset)\n",
    "        return list_dataset\n",
    "    \n",
    "    def generate_clients(self):\n",
    "        dataset=self.split_dataset_1label()\n",
    "        id=0\n",
    "        for shard in dataset:\n",
    "            self.client_list.append(Client(id=id,model=copy.deepcopy(self.model),dataset=shard,config=self.config['client']))\n",
    "            id+=1\n",
    "\n",
    "    def collect_clients_params(self):\n",
    "        client_params=[]\n",
    "        for index in range(0,len(self.round_dices)):\n",
    "            client_params.append(self.client_list[index].model.state_dict())\n",
    "        return client_params\n",
    "\n",
    "    def update_client_model(self,params):\n",
    "        for client in self.client_list:\n",
    "            client.model.load_state_dict(copy.deepcopy(params))\n",
    "        self.model.load_state_dict(copy.deepcopy(params))\n",
    "        print('Clients updated ! Ready for next round')    \n",
    "\n",
    "    def fedAvg(self):\n",
    "        total_len=0\n",
    "        for index in self.round_dices:\n",
    "            total_len+=len(self.client_list[index])\n",
    "\n",
    "        global_model_weights = copy.deepcopy(self.model.state_dict())\n",
    "        for key in global_model_weights:\n",
    "            global_model_weights[key] = torch.zeros_like(\n",
    "                global_model_weights[key])\n",
    "        \n",
    "        #server_params=copy.deepcopy(self.centralModel.parameters())\n",
    "\n",
    "        coef=torch.tensor([len(self.client_list[index])/total_len for index in self.round_dices])\n",
    "        for index in range(0,len(self.round_dices)):\n",
    "            local_model_weights = copy.deepcopy(self.client_list[index].model.state_dict())\n",
    "            for key in global_model_weights:\n",
    "                if str(global_model_weights[key].type())!='torch.LongTensor':\n",
    "\n",
    "                    global_model_weights[key] += (coef[index] * local_model_weights[key])\n",
    "        return global_model_weights\n",
    "\n",
    "    def metric(self,pred,label):\n",
    "        metric=MulticlassAccuracy(num_classes=21)\n",
    "        \n",
    "        return metric(pred,label).item()\n",
    "\n",
    "    def wandb_log(self,log={}):\n",
    "        try:\n",
    "            wandb.log(log)\n",
    "        except:\n",
    "            print('Wandb logging error server', )\n",
    "            \n",
    "    def evaluate(self,dataset,round):\n",
    "        self.model.eval()\n",
    "        criterion=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        dataloader=torch.utils.data.DataLoader(dataset,batch_size=int(10),shuffle=True)\n",
    "        run=wandb.init(group=\"federated_Evaluation\",job_type='Evaluation', project=PROJNAME)\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        test_loss=0.0\n",
    "        step=0\n",
    "        accuracyHist=[]\n",
    "        self.model=self.model.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x,y in dataloader:\n",
    "                x,y=x.to(device),y.to(device)\n",
    "                output=self.model(x)\n",
    "                loss=criterion(pred,y)\n",
    "\n",
    "                \n",
    "                x,y=x.cpu(),y.cpu()\n",
    "                output=output.cpu().detach()\n",
    "                \n",
    "                test_loss+=loss.item()\n",
    "                step+=1\n",
    "                pred=output.argmax(dim=1,keepdim=True).T[0]\n",
    "                accuracyHist.append(self.metric(pred,y))\n",
    "\n",
    "        accuracy=np.mean(accuracyHist)\n",
    "        loss=test_loss/step\n",
    "        if(accuracy>self.best_accuracy):\n",
    "            model_log = wandb.Artifact('best_eval_accuracy', type='model')\n",
    "            try:\n",
    "                self.best_accuracy=accuracy\n",
    "                model_log.add_file(self.save_model())\n",
    "                run.log_artifact(model_log)\n",
    "                print('model saved, best accuracy: {}'.format(self.best_accuracy))\n",
    "            except:\n",
    "                print('save model failed')\n",
    "        print('Evaluation successfully, ')\n",
    "        print('Round : {} ,Accuracy : {} loss : {} '.format(round,accuracy,loss))\n",
    "        self.wandb_log({\n",
    "                'round':round,\n",
    "                'loss':loss,\n",
    "                'accuracy':accuracy\n",
    "                })\n",
    "        self.model=self.model.to('cpu')\n",
    "        return accuracy\n",
    "    \n",
    "    def save_model(self):\n",
    "        file_name='bestmodel.h5'\n",
    "        torch.save(self.model.state_dict(), file_name)\n",
    "        return file_name\n",
    "    \n",
    "    def round_train(self):\n",
    "        from random import sample\n",
    "        for round in range(0,self.config['server']['num_round']):\n",
    "            \n",
    "            self.round_dices=sample(range(0,len(self)),self.config['server']['num_client_round'])\n",
    "            print('Round {}',format(round))\n",
    "            print('Including clients: {}'.format(self.round_dices))\n",
    "            for index in self.round_dices:\n",
    "                self.client_list[index].train_gpu(round=round)\n",
    "            print('Finish training. Collecting parameters...')\n",
    "            self.collect_clients_params()\n",
    "            params=self.fedAvg()\n",
    "            self.update_client_model(params=params)\n",
    "            acc=self.evaluate(self.eval_dataset,round=round)\n",
    "\n",
    "                \n",
    "            \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONFIG={\n",
    "    'client':{\n",
    "    'learning_rate':0.00006824,\n",
    "    'batch_size':16,\n",
    "    'weight_decay':0.000001,\n",
    "    'epoch':1,\n",
    "    },\n",
    "    'server':{\n",
    "        'num_client':100,\n",
    "        'num_client_round':3,\n",
    "        'num_round':50,\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round {} 0\n",
      "Including clients: [62, 55, 57]\n",
      "Client 62 start Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 , loss: 1.267372236468575, accuracy: 0.04061327645216476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoc</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.04061</td></tr><tr><td>epoc</td><td>0</td></tr><tr><td>loss</td><td>1.26737</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync f:\\Thesis\\Model train\\Federated_training_plantVillage\\wandb\\offline-run-20221212_230053-29n5ljx1<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\offline-run-20221212_230053-29n5ljx1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 55 start Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 , loss: 1.2706470066850835, accuracy: 0.040468976337631996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoc</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.04047</td></tr><tr><td>epoc</td><td>0</td></tr><tr><td>loss</td><td>1.27065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync f:\\Thesis\\Model train\\Federated_training_plantVillage\\wandb\\offline-run-20221212_230111-11knl0qq<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\offline-run-20221212_230111-11knl0qq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 57 start Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 , loss: 1.2719724224372344, accuracy: 0.0406673889903521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoc</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.04067</td></tr><tr><td>epoc</td><td>0</td></tr><tr><td>loss</td><td>1.27197</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync f:\\Thesis\\Model train\\Federated_training_plantVillage\\wandb\\offline-run-20221212_230126-1lkzj6lf<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\offline-run-20221212_230126-1lkzj6lf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training. Collecting parameters...\n",
      "Clients updated ! Ready for next round\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved, best accuracy: 0.0028694090866093914\n",
      "Evaluation successfully, \n",
      "Round : 0 ,Accuracy : 0.0028694090866093914 loss : 3.524852437718592 \n",
      "Round {} 1\n",
      "Including clients: [35, 36, 62]\n",
      "Client 35 start Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3lzz7rb0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>round</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.00287</td></tr><tr><td>loss</td><td>3.52485</td></tr><tr><td>round</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync f:\\Thesis\\Model train\\Federated_training_plantVillage\\wandb\\offline-run-20221212_230145-3lzz7rb0<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\offline-run-20221212_230145-3lzz7rb0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3lzz7rb0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Thesis\\Model train\\Federated_training_plantVillage\\federated_training.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m ser\u001b[39m=\u001b[39mServer(dataset\u001b[39m=\u001b[39mtrain,eval_dataset\u001b[39m=\u001b[39mtest_data,config\u001b[39m=\u001b[39mCONFIG)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m ser\u001b[39m.\u001b[39mgenerate_clients()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m ser\u001b[39m.\u001b[39;49mround_train()\n",
      "\u001b[1;32mf:\\Thesis\\Model train\\Federated_training_plantVillage\\federated_training.ipynb Cell 9\u001b[0m in \u001b[0;36mServer.round_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mIncluding clients: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_dices))\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_dices:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient_list[index]\u001b[39m.\u001b[39;49mtrain_gpu(\u001b[39mround\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mround\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFinish training. Collecting parameters...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollect_clients_params()\n",
      "\u001b[1;32mf:\\Thesis\\Model train\\Federated_training_plantVillage\\federated_training.ipynb Cell 9\u001b[0m in \u001b[0;36mClient.train_gpu\u001b[1;34m(self, round)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m step\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m epoc_accuracy\u001b[39m=\u001b[39m[]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     x,y\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mto(train_device),y\u001b[39m.\u001b[39mto(train_device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     pred\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\pytorchGPUI\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\pytorchGPUI\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\pytorchGPUI\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\pytorchGPUI\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mf:\\Thesis\\Model train\\Federated_training_plantVillage\\federated_training.ipynb Cell 9\u001b[0m in \u001b[0;36mplantVillage.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         img_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_labels[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m][idx])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         image \u001b[39m=\u001b[39m (read_image(img_path)\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mResize((\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m-\u001b[39m\u001b[39m0.7898\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.4373\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.6051\u001b[39m), (\u001b[39m1.3209\u001b[39m, \u001b[39m1.5867\u001b[39m, \u001b[39m1.1863\u001b[39m))])\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training_plantVillage/federated_training.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\pytorchGPUI\\lib\\site-packages\\torchvision\\io\\image.py:245\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[0;32m    244\u001b[0m     _log_api_usage_once(read_image)\n\u001b[1;32m--> 245\u001b[0m data \u001b[39m=\u001b[39m read_file(path)\n\u001b[0;32m    246\u001b[0m \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\pytorchGPUI\\lib\\site-packages\\torchvision\\io\\image.py:47\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[0;32m     46\u001b[0m     _log_api_usage_once(read_file)\n\u001b[1;32m---> 47\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mread_file(path)\n\u001b[0;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = '761f77141558010f4d706f726fcf122aac0aae23'\n",
    "os.environ[\"WANDB_MODE\"]=\"offline\"\n",
    "\n",
    "PROJNAME='fed_train19'\n",
    "import wandb\n",
    "df=pd.read_csv('./plantVillage.csv')\n",
    "df: DataFrame=df.drop('Unnamed: 0',axis=1)\n",
    "train,valid_test=train_test_split(df,test_size=0.2)\n",
    "valid,test=train_test_split(valid_test,test_size=0.5)\n",
    "\n",
    "train_data=plantVillage(df=train.reset_index())\n",
    "test_data=plantVillage(df=test.reset_index())\n",
    "valid_data=plantVillage(df=valid.reset_index())\n",
    "\n",
    "model=models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1]=(torch.nn.Linear(in_features=1280, out_features=21, bias=True))\n",
    "\n",
    "\n",
    "# note that we define values from `wandb.config` instead \n",
    "# of defining hard values\n",
    "\n",
    "config = {\n",
    "    \"lr\": 0.00006824,\n",
    "    \"batch_size\":16,\n",
    "    \"epoch\":20\n",
    "}\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "train=train.reset_index(drop=True)\n",
    "ser=Server(dataset=train,eval_dataset=test_data,config=CONFIG)\n",
    "ser.generate_clients()\n",
    "ser.round_train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Thesis\\Model train\\Federated_training\\federated_training.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tensor([[[ \u001b[39m0.0132\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0043\u001b[39m,  \u001b[39m0.0148\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m          [ \u001b[39m0.0328\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0254\u001b[39m,  \u001b[39m0.0069\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m          [ \u001b[39m0.0105\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0373\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0147\u001b[39m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         [[ \u001b[39m0.0080\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0059\u001b[39m,  \u001b[39m0.0151\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m          [ \u001b[39m0.0200\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0329\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0021\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m          [ \u001b[39m0.0114\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0330\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0079\u001b[39m]],\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         [[\u001b[39m-\u001b[39m\u001b[39m0.0252\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0202\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0100\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m          [\u001b[39m-\u001b[39m\u001b[39m0.0112\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0293\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0152\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m          [\u001b[39m-\u001b[39m\u001b[39m0.0265\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0334\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.0242\u001b[39m]]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "tensor([[[ 0.0132, -0.0043,  0.0148],\n",
    "         [ 0.0328, -0.0254,  0.0069],\n",
    "         [ 0.0105, -0.0373, -0.0147]],\n",
    "\n",
    "        [[ 0.0080, -0.0059,  0.0151],\n",
    "         [ 0.0200, -0.0329, -0.0021],\n",
    "         [ 0.0114, -0.0330, -0.0079]],\n",
    "\n",
    "        [[-0.0252, -0.0202, -0.0100],\n",
    "         [-0.0112, -0.0293, -0.0152],\n",
    "         [-0.0265, -0.0334, -0.0242]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0142, -0.0026,  0.0154],\n",
       "         [ 0.0329, -0.0226,  0.0078],\n",
       "         [ 0.0119, -0.0340, -0.0124]],\n",
       "\n",
       "        [[ 0.0086, -0.0047,  0.0139],\n",
       "         [ 0.0195, -0.0303, -0.0018],\n",
       "         [ 0.0117, -0.0305, -0.0070]],\n",
       "\n",
       "        [[-0.0226, -0.0172, -0.0079],\n",
       "         [-0.0095, -0.0260, -0.0126],\n",
       "         [-0.0241, -0.0300, -0.0211]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.client_list[2].model.state_dict()['features.0.0.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Thesis\\Model train\\Federated_training\\federated_training.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Federated_training/federated_training.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ser\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ser' is not defined"
     ]
    }
   ],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 16% | 50% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 16% |  8% |\n"
     ]
    }
   ],
   "source": [
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "\n",
    "free_gpu_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorchGPUI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8b858f47e475f096c0bf0df9132e4b2b12ebb02cb87303e1af43904bc641e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
