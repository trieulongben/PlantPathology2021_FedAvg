{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "import multiprocessing as mp\n",
    "from re import T\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "#from model import net\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torchvision import datasets,transforms\n",
    "import random\n",
    "from torch import optim,ceil\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class plantdisease(Dataset):\n",
    "    def __init__(self, df,\n",
    "                  img_dir='data/oneFolder'\n",
    "                 , isTest=False):\n",
    "        self.img_labels=df\n",
    "        self.img_dir='../../Data/DataResized512/'\n",
    "       # self.train, self.test = train_test_split(self.img_labels, test_size=0.05)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels['image'][idx])\n",
    "\n",
    "            image = (read_image(img_path).float())\n",
    "            self.transform=transforms.Compose([transforms.Resize((342,512)),\n",
    "        transforms.Normalize((124.4455, 159.9584, 104.1832), (47.1528, 41.4626, 49.2424))])\n",
    "            image = self.transform(image)\n",
    "            label = self.img_labels['labels'][idx]\n",
    "            label=np.fromstring(label[1:-1], dtype=np.int,sep=',')\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\ttorch.cuda.empty_cache()\n",
    "\tprint(\"Total size:\", total_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../Data/data10k.csv')\n",
    "df=df.drop('Unnamed: 0',axis=1)\n",
    "train,valid_test=train_test_split(df,test_size=0.2)\n",
    "valid,test=train_test_split(valid_test,test_size=0.5)\n",
    "\n",
    "train_data=plantdisease(df=train.reset_index())\n",
    "test_data=plantdisease(df=test.reset_index())\n",
    "valid_data=plantdisease(df=valid.reset_index())\n",
    "\n",
    "model=models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1]=(torch.nn.Linear(in_features=1280, out_features=6, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "\n",
    "    dump_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confusion_matrixCal(target,pred):\n",
    "  matrix=0\n",
    "  for i in range(0,target.shape[0]):\n",
    "    matrix+=confusion_matrix(target[i], pred[i],labels=[1, 0])\n",
    "  return matrix\n",
    "\n",
    "#Test train function\n",
    "\n",
    "config = {\n",
    "        \"lr\": 0.0001,\n",
    "        \"batch_size\": 6\n",
    "        ,\"epoch\":20\n",
    "    }\n",
    "def client_trainGPU(config):\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  optimizer =optim.Adam(model.parameters(),lr=config[\"lr\"],weight_decay=9e-05)\n",
    "\n",
    "  train_dataloader=DataLoader(train_data,batch_size=int(config[\"batch_size\"]))\n",
    "  test_dataloader=DataLoader(test_data,batch_size=int(config[\"batch_size\"]))\n",
    "  valid_dataloader=DataLoader(valid_data,batch_size=int(config[\"batch_size\"]))\n",
    "\n",
    "  lossHist=[]\n",
    "  lossHist_test=[]\n",
    "\n",
    "\n",
    "  for epoc in range(config['epoch']):\n",
    "      model.to(device)\n",
    "      #\n",
    "      total=0\n",
    "#\n",
    "      correct=0\n",
    "      train_loss = 0.0\n",
    "      confusionMatrix=0\n",
    "      accuracyHist=[]\n",
    "      train_step=0\n",
    "      print('start Epoch ',epoc)\n",
    "      for i, datas in enumerate(((train_dataloader)),0):\n",
    "          data, target=datas\n",
    "          data,target=data.to(device),target.to(device)\n",
    "          \n",
    "          \n",
    "          output = model(data)\n",
    "\n",
    "          loss = torch.nn.BCEWithLogitsLoss()(output, target.float())\n",
    "\n",
    "          train_loss += loss.item()\n",
    "          train_step+=1\n",
    "\n",
    "\n",
    "          ouput=torch.sigmoid(output)\n",
    "          predicted = torch.round(ouput)\n",
    "          target=target.cpu().detach()\n",
    "          data=data.cpu().detach()\n",
    "          predicted=predicted.cpu().detach()\n",
    "          accuracyHist.append(accuracy_score(target,predicted))\n",
    "          confusionMatrix+=confusion_matrixCal(target,predicted)\n",
    "          optimizer.zero_grad(set_to_none=True)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "      print('Client ID ',  ', epoch ',\n",
    "        epoc, ': ', train_loss / int(config[\"batch_size\"]))\n",
    "      lossHist.append(train_loss / int(config[\"batch_size\"]))\n",
    "      print('accuracy {}'.format(np.mean(accuracyHist)))  \n",
    "\n",
    "      #Evaluation\n",
    "\n",
    "      ######\n",
    "      confusionMatrix_test=0\n",
    "      accuracyHist_test=[]\n",
    "      test_loss = 0.0\n",
    "      test_step=0\n",
    "      model.cpu()\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        for i, datas in enumerate(((test_dataloader)),0):\n",
    "            data, target=datas\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            loss = torch.nn.BCEWithLogitsLoss()(output, target.float())\n",
    "            ouput=torch.sigmoid(output)\n",
    "            predicted = np.round(ouput)\n",
    "            total += target.size(0)\n",
    "            test_loss += loss.item()\n",
    "            test_step+=1\n",
    "\n",
    "            accuracyHist_test.append(accuracy_score(target,predicted))\n",
    "            confusionMatrix_test+=confusion_matrixCal(target,predicted)\n",
    "      print('test_loss {}'.format(test_loss/test_step))\n",
    "      lossHist_test.append(test_loss/test_step)\n",
    "      print('accuracy {}'.format(np.mean(accuracyHist_test)))\n",
    "      train_loss=train_loss / train_step\n",
    "      test_loss=test_loss/test_step\n",
    "\n",
    "      TP_test=confusionMatrix_test[0][0]\n",
    "      FP_test=confusionMatrix_test[0][1]\n",
    "      FN_test=confusionMatrix_test[1][0]\n",
    "      TN_test=confusionMatrix_test[1][1]\n",
    "      accuracy_test=(TP_test+TN_test)/(FP_test+FN_test+TP_test+TN_test)\n",
    "      recal_test=TP_test/(TP_test+FN_test)\n",
    "      precision_test=TP_test/(TP_test+FP_test)\n",
    "      negativePredictiveValue_test=TN_test/(TN_test+FN_test)\n",
    "      missRate_test=FN_test/(TP_test+FN_test)\n",
    "      fallOut_test=FP_test/(TN_test+FP_test)\n",
    "      f1_test=(2*precision_test*recal_test)/(precision_test+recal_test)\n",
    "\n",
    "\n",
    "      TP_train=confusionMatrix[0][0]\n",
    "      FP_train=confusionMatrix[0][1]\n",
    "      FN_train=confusionMatrix[1][0]\n",
    "      TN_train=confusionMatrix[1][1]\n",
    "      accuracy_train=(TP_train+TN_train)/(FP_train+FN_train+TP_train+TN_train)\n",
    "      recal_train=TP_train/(TP_train+FN_train)\n",
    "      precision_train=TP_train/(TP_train+FP_train)\n",
    "      negativePredictiveValue_train=TN_train/(TN_train+FN_train)\n",
    "      missRate_train=FN_train/(TP_train+FN_train)\n",
    "      fallOut_train=FP_train/(TN_train+FP_train)\n",
    "      f1_train=(2*precision_train*recal_train)/(precision_train+recal_train)\n",
    "\n",
    "      wandb.log({\n",
    "            'epoc': epoc, \n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': test_loss,\n",
    "\n",
    "            \n",
    "            'TP_test':TP_test,\n",
    "            'FP_test':FP_test,\n",
    "            'FN_test':FN_test,\n",
    "            'TN_test':TN_test,\n",
    "            'accuracy_test':accuracy_test,\n",
    "            'recal_test':recal_test,\n",
    "            'precision_test':precision_test,\n",
    "            'negativePredictiveValue_test':negativePredictiveValue_test,\n",
    "            'f1_test':f1_test,\n",
    "\n",
    "\n",
    "            'TP':TP_train,\n",
    "            'FP':FP_train,\n",
    "            'FN':FN_train,\n",
    "            'TN':TN_train,\n",
    "            'accuracy_train':accuracy_train,\n",
    "            'recal_train':recal_train,\n",
    "            'precision_train':precision_train,\n",
    "            'negativePredictiveValue_train':negativePredictiveValue_train,\n",
    "            'f1_train':f1_train,\n",
    "          })\n",
    "\n",
    "  free_gpu_cache()\n",
    "  print(\"Finished Training\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 0metq8be\n",
      "Sweep URL: https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "# Define sweep config\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'maximize', 'name': 'val_acc'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'batch_size': {'values': [8,16]},\n",
    "        'epochs': {'values': [5]},\n",
    "        'lr': {'max': 0.0002, 'min': 0.00001}\n",
    "     }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project='modeltunning_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5yzdd0zf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 5.7166084355680035e-05\n",
      "e:\\Anaconda\\envs\\pytorchGPUI\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmakkuror\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221130_222753-5yzdd0zf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/5yzdd0zf\" target=\"_blank\">true-sweep-1</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  27.24395285313949\n",
      "accuracy 0.6365\n",
      "test_loss 0.12094356102496386\n",
      "accuracy 0.806\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  17.1249247577216\n",
      "accuracy 0.785875\n",
      "test_loss 0.1400116395931691\n",
      "accuracy 0.788\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  13.200377291825134\n",
      "accuracy 0.83525\n",
      "test_loss 0.13196187509596347\n",
      "accuracy 0.805\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  11.186544140378828\n",
      "accuracy 0.85775\n",
      "test_loss 0.12909394036978483\n",
      "accuracy 0.817\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  9.933420970788575\n",
      "accuracy 0.86725\n",
      "test_loss 0.13631849508918822\n",
      "accuracy 0.794\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 19% | 75% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 19% | 35% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▅▃▁▁</td></tr><tr><td>FN_test</td><td>▁▅█▄▃</td></tr><tr><td>FP</td><td>█▄▂▂▁</td></tr><tr><td>FP_test</td><td>▁█▁▁▇</td></tr><tr><td>TN</td><td>▁▄▆██</td></tr><tr><td>TN_test</td><td>█▄▁▅▆</td></tr><tr><td>TP</td><td>▁▅▇▇█</td></tr><tr><td>TP_test</td><td>█▁██▂</td></tr><tr><td>accuracy_test</td><td>█▁▂▆▄</td></tr><tr><td>accuracy_train</td><td>▁▅▇██</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>█▁▃▆▄</td></tr><tr><td>f1_train</td><td>▁▅▇██</td></tr><tr><td>negativePredictiveValue_test</td><td>█▄▁▅▆</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▄▆██</td></tr><tr><td>precision_test</td><td>█▁██▂</td></tr><tr><td>precision_train</td><td>▁▅▇▇█</td></tr><tr><td>recal_test</td><td>█▃▁▅▆</td></tr><tr><td>recal_train</td><td>▁▅▇██</td></tr><tr><td>train_loss</td><td>█▄▂▂▁</td></tr><tr><td>val_loss</td><td>▁█▅▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>609</td></tr><tr><td>FN_test</td><td>108</td></tr><tr><td>FP</td><td>917</td></tr><tr><td>FP_test</td><td>203</td></tr><tr><td>TN</td><td>38715</td></tr><tr><td>TN_test</td><td>4799</td></tr><tr><td>TP</td><td>7759</td></tr><tr><td>TP_test</td><td>890</td></tr><tr><td>accuracy_test</td><td>0.94817</td></tr><tr><td>accuracy_train</td><td>0.96821</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.85127</td></tr><tr><td>f1_train</td><td>0.91047</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97799</td></tr><tr><td>negativePredictiveValue_train</td><td>0.98451</td></tr><tr><td>precision_test</td><td>0.81427</td></tr><tr><td>precision_train</td><td>0.89431</td></tr><tr><td>recal_test</td><td>0.89178</td></tr><tr><td>recal_train</td><td>0.92722</td></tr><tr><td>train_loss</td><td>0.07947</td></tr><tr><td>val_loss</td><td>0.13632</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-1</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/5yzdd0zf\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/5yzdd0zf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221130_222753-5yzdd0zf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q6i65ubw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001871871344794208\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221130_225225-q6i65ubw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/q6i65ubw\" target=\"_blank\">neat-sweep-2</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  3.5258123546664137\n",
      "accuracy 0.818625\n",
      "test_loss 0.18026166935525242\n",
      "accuracy 0.7123015873015873\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  3.1002451936074067\n",
      "accuracy 0.8425\n",
      "test_loss 0.14897509498728645\n",
      "accuracy 0.7628968253968254\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  2.9182662490347866\n",
      "accuracy 0.849\n",
      "test_loss 0.18339872023179418\n",
      "accuracy 0.7212301587301587\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  2.67217517154495\n",
      "accuracy 0.85925\n",
      "test_loss 0.15510335937142372\n",
      "accuracy 0.7797619047619048\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  2.6212627569766482\n",
      "accuracy 0.86225\n",
      "test_loss 0.1284871111431765\n",
      "accuracy 0.8134920634920635\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 92% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 14% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cd9205538b447fbe4fbe252fd40a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.020 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.058192…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▄▃▁▁</td></tr><tr><td>FN_test</td><td>█▁▆▃▃</td></tr><tr><td>FP</td><td>█▅▄▁▁</td></tr><tr><td>FP_test</td><td>▇▇█▅▁</td></tr><tr><td>TN</td><td>▁▅▆██</td></tr><tr><td>TN_test</td><td>▁█▃▆▆</td></tr><tr><td>TP</td><td>▁▄▅██</td></tr><tr><td>TP_test</td><td>▂▂▁▄█</td></tr><tr><td>accuracy_test</td><td>▁▅▁▅█</td></tr><tr><td>accuracy_train</td><td>▁▄▆██</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▁▄▁▅█</td></tr><tr><td>f1_train</td><td>▁▄▆██</td></tr><tr><td>negativePredictiveValue_test</td><td>▁█▃▆▆</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▅▆██</td></tr><tr><td>precision_test</td><td>▂▂▁▄█</td></tr><tr><td>precision_train</td><td>▁▄▅██</td></tr><tr><td>recal_test</td><td>▁█▂▆▇</td></tr><tr><td>recal_train</td><td>▁▅▆██</td></tr><tr><td>train_loss</td><td>█▅▃▁▁</td></tr><tr><td>val_loss</td><td>█▄█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>631</td></tr><tr><td>FN_test</td><td>111</td></tr><tr><td>FP</td><td>974</td></tr><tr><td>FP_test</td><td>184</td></tr><tr><td>TN</td><td>38693</td></tr><tr><td>TN_test</td><td>4796</td></tr><tr><td>TP</td><td>7702</td></tr><tr><td>TP_test</td><td>909</td></tr><tr><td>accuracy_test</td><td>0.95083</td></tr><tr><td>accuracy_train</td><td>0.96656</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.86039</td></tr><tr><td>f1_train</td><td>0.90564</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97738</td></tr><tr><td>negativePredictiveValue_train</td><td>0.98395</td></tr><tr><td>precision_test</td><td>0.83166</td></tr><tr><td>precision_train</td><td>0.88774</td></tr><tr><td>recal_test</td><td>0.89118</td></tr><tr><td>recal_train</td><td>0.92428</td></tr><tr><td>train_loss</td><td>0.08388</td></tr><tr><td>val_loss</td><td>0.12849</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">neat-sweep-2</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/q6i65ubw\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/q6i65ubw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221130_225225-q6i65ubw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k8yd2l19 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 4.6327648333204674e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413ffbc5adcb41988621b2c13fbceae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221130_232209-k8yd2l19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/k8yd2l19\" target=\"_blank\">crisp-sweep-3</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  1.6252341352810618\n",
      "accuracy 0.911625\n",
      "test_loss 0.1262924773766408\n",
      "accuracy 0.8353174603174603\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  1.1007817631325452\n",
      "accuracy 0.9425\n",
      "test_loss 0.13376181590415182\n",
      "accuracy 0.8392857142857143\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.7734865078273288\n",
      "accuracy 0.9595\n",
      "test_loss 0.15531682631643934\n",
      "accuracy 0.8402777777777778\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.5482180729441097\n",
      "accuracy 0.97\n",
      "test_loss 0.17509235221419542\n",
      "accuracy 0.8323412698412699\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.5082731140655596\n",
      "accuracy 0.973125\n",
      "test_loss 0.2025907402645634\n",
      "accuracy 0.8234126984126984\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 93% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 15% |\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▄▂▁▁</td></tr><tr><td>FN_test</td><td>▂▅▁▅█</td></tr><tr><td>FP</td><td>█▄▂▁▁</td></tr><tr><td>FP_test</td><td>█▁▂▁▃</td></tr><tr><td>TN</td><td>▁▅▇██</td></tr><tr><td>TN_test</td><td>▇▄█▅▁</td></tr><tr><td>TP</td><td>▁▅▇██</td></tr><tr><td>TP_test</td><td>▁█▇█▆</td></tr><tr><td>accuracy_test</td><td>▃▅█▆▁</td></tr><tr><td>accuracy_train</td><td>▁▅▇██</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▂▅█▆▁</td></tr><tr><td>f1_train</td><td>▁▅▇██</td></tr><tr><td>negativePredictiveValue_test</td><td>▇▄█▄▁</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▅▇██</td></tr><tr><td>precision_test</td><td>▁█▇█▆</td></tr><tr><td>precision_train</td><td>▁▅▇██</td></tr><tr><td>recal_test</td><td>▆▄█▅▁</td></tr><tr><td>recal_train</td><td>▁▅▇██</td></tr><tr><td>train_loss</td><td>█▅▃▁▁</td></tr><tr><td>val_loss</td><td>▁▂▄▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>87</td></tr><tr><td>FN_test</td><td>135</td></tr><tr><td>FP</td><td>157</td></tr><tr><td>FP_test</td><td>142</td></tr><tr><td>TN</td><td>39237</td></tr><tr><td>TN_test</td><td>4772</td></tr><tr><td>TP</td><td>8519</td></tr><tr><td>TP_test</td><td>951</td></tr><tr><td>accuracy_test</td><td>0.95383</td></tr><tr><td>accuracy_train</td><td>0.99492</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.87288</td></tr><tr><td>f1_train</td><td>0.98588</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97249</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99779</td></tr><tr><td>precision_test</td><td>0.87008</td></tr><tr><td>precision_train</td><td>0.9819</td></tr><tr><td>recal_test</td><td>0.87569</td></tr><tr><td>recal_train</td><td>0.98989</td></tr><tr><td>train_loss</td><td>0.01626</td></tr><tr><td>val_loss</td><td>0.20259</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crisp-sweep-3</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/k8yd2l19\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/k8yd2l19</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221130_232209-k8yd2l19\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p36mb919 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00017768609445864602\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221130_234944-p36mb919</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/p36mb919\" target=\"_blank\">cerulean-sweep-4</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  1.6357564260051731\n",
      "accuracy 0.91275\n",
      "test_loss 0.14788562360973584\n",
      "accuracy 0.8125\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  1.5134508695846307\n",
      "accuracy 0.9115\n",
      "test_loss 0.19495192725980093\n",
      "accuracy 0.7628968253968254\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  1.558892457622278\n",
      "accuracy 0.91325\n",
      "test_loss 0.16898344511107083\n",
      "accuracy 0.8115079365079365\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  1.3640993230183085\n",
      "accuracy 0.921125\n",
      "test_loss 0.1983848759954858\n",
      "accuracy 0.808531746031746\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  1.4803848388510232\n",
      "accuracy 0.919375\n",
      "test_loss 0.17755642134903205\n",
      "accuracy 0.7946428571428571\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 94% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 16% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cf021cac754662b62c56ef6c65c970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▇▇▁▂</td></tr><tr><td>FN_test</td><td>▁█▃▂▄</td></tr><tr><td>FP</td><td>██▆▁▃</td></tr><tr><td>FP_test</td><td>▅▇▁▅█</td></tr><tr><td>TN</td><td>▁▂▂█▇</td></tr><tr><td>TN_test</td><td>█▁▆▇▅</td></tr><tr><td>TP</td><td>▁▁▃█▆</td></tr><tr><td>TP_test</td><td>▅▂█▄▁</td></tr><tr><td>accuracy_test</td><td>▇▁█▆▃</td></tr><tr><td>accuracy_train</td><td>▁▁▃█▇</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▇▁█▆▃</td></tr><tr><td>f1_train</td><td>▁▁▃█▇</td></tr><tr><td>negativePredictiveValue_test</td><td>█▁▆▇▅</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▂▂█▇</td></tr><tr><td>precision_test</td><td>▅▂█▄▁</td></tr><tr><td>precision_train</td><td>▁▁▃█▆</td></tr><tr><td>recal_test</td><td>█▁▆▇▅</td></tr><tr><td>recal_train</td><td>▁▂▂█▇</td></tr><tr><td>train_loss</td><td>█▅▆▁▄</td></tr><tr><td>val_loss</td><td>▁█▄█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>340</td></tr><tr><td>FN_test</td><td>154</td></tr><tr><td>FP</td><td>481</td></tr><tr><td>FP_test</td><td>200</td></tr><tr><td>TN</td><td>38984</td></tr><tr><td>TN_test</td><td>4753</td></tr><tr><td>TP</td><td>8195</td></tr><tr><td>TP_test</td><td>893</td></tr><tr><td>accuracy_test</td><td>0.941</td></tr><tr><td>accuracy_train</td><td>0.9829</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.83458</td></tr><tr><td>f1_train</td><td>0.9523</td></tr><tr><td>negativePredictiveValue_test</td><td>0.96862</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99135</td></tr><tr><td>precision_test</td><td>0.81702</td></tr><tr><td>precision_train</td><td>0.94456</td></tr><tr><td>recal_test</td><td>0.85291</td></tr><tr><td>recal_train</td><td>0.96016</td></tr><tr><td>train_loss</td><td>0.04737</td></tr><tr><td>val_loss</td><td>0.17756</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cerulean-sweep-4</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/p36mb919\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/p36mb919</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221130_234944-p36mb919\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s4ty5uat with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 9.77746165459832e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0752f6a1a30442191a542aef96ce23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_001932-s4ty5uat</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/s4ty5uat\" target=\"_blank\">swift-sweep-5</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.9246999895603949\n",
      "accuracy 0.946875\n",
      "test_loss 0.21693783202430322\n",
      "accuracy 0.8204365079365079\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.656567824128615\n",
      "accuracy 0.964\n",
      "test_loss 0.17976961630795682\n",
      "accuracy 0.8184523809523809\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.5176481835833329\n",
      "accuracy 0.96925\n",
      "test_loss 0.2348675910112751\n",
      "accuracy 0.8125\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.5003595455327741\n",
      "accuracy 0.9715\n",
      "test_loss 0.19802945783954956\n",
      "accuracy 0.8392857142857143\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.5033929315286514\n",
      "accuracy 0.97075\n",
      "test_loss 0.19665587542667276\n",
      "accuracy 0.816468253968254\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 95% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 17% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded89e9b0a4541f581d34e51943f4ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▃▂▁▁</td></tr><tr><td>FN_test</td><td>█▂▃▁▆</td></tr><tr><td>FP</td><td>█▃▁▁▁</td></tr><tr><td>FP_test</td><td>▂▆█▃▁</td></tr><tr><td>TN</td><td>▁▆▇██</td></tr><tr><td>TN_test</td><td>▁▇▆█▃</td></tr><tr><td>TP</td><td>▁▆███</td></tr><tr><td>TP_test</td><td>▇▃▁▆█</td></tr><tr><td>accuracy_test</td><td>▁▄▁█▄</td></tr><tr><td>accuracy_train</td><td>▁▆███</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▃▄▁█▅</td></tr><tr><td>f1_train</td><td>▁▆███</td></tr><tr><td>negativePredictiveValue_test</td><td>▁▇▆█▃</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▆▇██</td></tr><tr><td>precision_test</td><td>▇▃▁▆█</td></tr><tr><td>precision_train</td><td>▁▆███</td></tr><tr><td>recal_test</td><td>▁▆▆█▃</td></tr><tr><td>recal_train</td><td>▁▆▇██</td></tr><tr><td>train_loss</td><td>█▄▁▁▁</td></tr><tr><td>val_loss</td><td>▆▁█▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>100</td></tr><tr><td>FN_test</td><td>149</td></tr><tr><td>FP</td><td>172</td></tr><tr><td>FP_test</td><td>138</td></tr><tr><td>TN</td><td>39224</td></tr><tr><td>TN_test</td><td>4758</td></tr><tr><td>TP</td><td>8504</td></tr><tr><td>TP_test</td><td>955</td></tr><tr><td>accuracy_test</td><td>0.95217</td></tr><tr><td>accuracy_train</td><td>0.99433</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.86937</td></tr><tr><td>f1_train</td><td>0.98426</td></tr><tr><td>negativePredictiveValue_test</td><td>0.96964</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99746</td></tr><tr><td>precision_test</td><td>0.87374</td></tr><tr><td>precision_train</td><td>0.98018</td></tr><tr><td>recal_test</td><td>0.86504</td></tr><tr><td>recal_train</td><td>0.98838</td></tr><tr><td>train_loss</td><td>0.01611</td></tr><tr><td>val_loss</td><td>0.19666</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">swift-sweep-5</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/s4ty5uat\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/s4ty5uat</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_001932-s4ty5uat\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ygsc0ko5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00015013258827327314\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa6e6f7c6a7458cbeb690b7f261fafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_004516-ygsc0ko5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/ygsc0ko5\" target=\"_blank\">sleek-sweep-6</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  5.092296098059251\n",
      "accuracy 0.9325\n",
      "test_loss 0.16831983676925302\n",
      "accuracy 0.792\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  5.217530240369342\n",
      "accuracy 0.9285\n",
      "test_loss 0.17395516133494676\n",
      "accuracy 0.787\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  4.947323170850723\n",
      "accuracy 0.9315\n",
      "test_loss 0.1816312909000553\n",
      "accuracy 0.817\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  4.901803395285242\n",
      "accuracy 0.9335\n",
      "test_loss 0.20604346175910904\n",
      "accuracy 0.793\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  4.276133090545045\n",
      "accuracy 0.939875\n",
      "test_loss 0.22004257922060788\n",
      "accuracy 0.777\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 63% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 23% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6118782875948359f684a92c9df1d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▇█▇▆▁</td></tr><tr><td>FN_test</td><td>▇▃▁█▄</td></tr><tr><td>FP</td><td>▇█▆▆▁</td></tr><tr><td>FP_test</td><td>▁▅▃▂█</td></tr><tr><td>TN</td><td>▂▁▂▃█</td></tr><tr><td>TN_test</td><td>▂▆█▁▅</td></tr><tr><td>TP</td><td>▂▁▃▃█</td></tr><tr><td>TP_test</td><td>█▄▆▇▁</td></tr><tr><td>accuracy_test</td><td>▆▅█▄▁</td></tr><tr><td>accuracy_train</td><td>▂▁▃▃█</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▇▅█▅▁</td></tr><tr><td>f1_train</td><td>▂▁▃▃█</td></tr><tr><td>negativePredictiveValue_test</td><td>▂▆█▁▅</td></tr><tr><td>negativePredictiveValue_train</td><td>▂▁▂▃█</td></tr><tr><td>precision_test</td><td>█▄▆▇▁</td></tr><tr><td>precision_train</td><td>▂▁▃▃█</td></tr><tr><td>recal_test</td><td>▂▆█▁▃</td></tr><tr><td>recal_train</td><td>▂▁▂▃█</td></tr><tr><td>train_loss</td><td>▇█▆▆▁</td></tr><tr><td>val_loss</td><td>▁▂▃▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>228</td></tr><tr><td>FN_test</td><td>159</td></tr><tr><td>FP</td><td>353</td></tr><tr><td>FP_test</td><td>221</td></tr><tr><td>TN</td><td>39096</td></tr><tr><td>TN_test</td><td>4748</td></tr><tr><td>TP</td><td>8323</td></tr><tr><td>TP_test</td><td>872</td></tr><tr><td>accuracy_test</td><td>0.93667</td></tr><tr><td>accuracy_train</td><td>0.9879</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.82109</td></tr><tr><td>f1_train</td><td>0.96627</td></tr><tr><td>negativePredictiveValue_test</td><td>0.9676</td></tr><tr><td>negativePredictiveValue_train</td><td>0.9942</td></tr><tr><td>precision_test</td><td>0.7978</td></tr><tr><td>precision_train</td><td>0.95931</td></tr><tr><td>recal_test</td><td>0.84578</td></tr><tr><td>recal_train</td><td>0.97334</td></tr><tr><td>train_loss</td><td>0.03421</td></tr><tr><td>val_loss</td><td>0.22004</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sleek-sweep-6</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/ygsc0ko5\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/ygsc0ko5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_004516-ygsc0ko5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nk8vaqj2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001590844245643104\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_011112-nk8vaqj2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/nk8vaqj2\" target=\"_blank\">graceful-sweep-7</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  4.5884007484683025\n",
      "accuracy 0.936375\n",
      "test_loss 0.17409856255166234\n",
      "accuracy 0.798\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  5.85262014444379\n",
      "accuracy 0.92325\n",
      "test_loss 0.22400216420227662\n",
      "accuracy 0.776\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  4.558713379308756\n",
      "accuracy 0.937875\n",
      "test_loss 0.18982658305577935\n",
      "accuracy 0.793\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  4.650463361183938\n",
      "accuracy 0.93475\n",
      "test_loss 0.273093723791535\n",
      "accuracy 0.778\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  4.278856065139735\n",
      "accuracy 0.940875\n",
      "test_loss 0.28351262043882164\n",
      "accuracy 0.741\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 63% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 23% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1267ea4121486ba2ec2b9e9ec7ff02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▄█▂▅▁</td></tr><tr><td>FN_test</td><td>▅▄▁█▇</td></tr><tr><td>FP</td><td>▃█▃▃▁</td></tr><tr><td>FP_test</td><td>▁▅▆▂█</td></tr><tr><td>TN</td><td>▅▁▇▄█</td></tr><tr><td>TN_test</td><td>▄▅█▁▂</td></tr><tr><td>TP</td><td>▆▁▆▆█</td></tr><tr><td>TP_test</td><td>█▃▃▇▁</td></tr><tr><td>accuracy_test</td><td>█▅█▅▁</td></tr><tr><td>accuracy_train</td><td>▆▁▆▅█</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>█▅▇▅▁</td></tr><tr><td>f1_train</td><td>▆▁▆▅█</td></tr><tr><td>negativePredictiveValue_test</td><td>▄▅█▁▂</td></tr><tr><td>negativePredictiveValue_train</td><td>▅▁▇▄█</td></tr><tr><td>precision_test</td><td>█▃▃▇▁</td></tr><tr><td>precision_train</td><td>▆▁▆▆█</td></tr><tr><td>recal_test</td><td>▄▅█▂▁</td></tr><tr><td>recal_train</td><td>▅▁▇▄█</td></tr><tr><td>train_loss</td><td>▂█▂▃▁</td></tr><tr><td>val_loss</td><td>▁▄▂▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>241</td></tr><tr><td>FN_test</td><td>203</td></tr><tr><td>FP</td><td>338</td></tr><tr><td>FP_test</td><td>231</td></tr><tr><td>TN</td><td>39083</td></tr><tr><td>TN_test</td><td>4704</td></tr><tr><td>TP</td><td>8338</td></tr><tr><td>TP_test</td><td>862</td></tr><tr><td>accuracy_test</td><td>0.92767</td></tr><tr><td>accuracy_train</td><td>0.98794</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.79889</td></tr><tr><td>f1_train</td><td>0.96644</td></tr><tr><td>negativePredictiveValue_test</td><td>0.95863</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99387</td></tr><tr><td>precision_test</td><td>0.78866</td></tr><tr><td>precision_train</td><td>0.96104</td></tr><tr><td>recal_test</td><td>0.80939</td></tr><tr><td>recal_train</td><td>0.97191</td></tr><tr><td>train_loss</td><td>0.03423</td></tr><tr><td>val_loss</td><td>0.28351</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">graceful-sweep-7</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/nk8vaqj2\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/nk8vaqj2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_011112-nk8vaqj2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a7fu20iw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00011368456549867728\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e53db89234a4f3aab54ba3908f889ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_013715-a7fu20iw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/a7fu20iw\" target=\"_blank\">sandy-sweep-8</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  2.8872398912562858\n",
      "accuracy 0.957125\n",
      "test_loss 0.21331221576104872\n",
      "accuracy 0.823\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  2.2651852617774466\n",
      "accuracy 0.966875\n",
      "test_loss 0.2052570833612699\n",
      "accuracy 0.806\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  2.209191108855066\n",
      "accuracy 0.968625\n",
      "test_loss 0.20795459525054322\n",
      "accuracy 0.81\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  2.068601325986265\n",
      "accuracy 0.970375\n",
      "test_loss 0.23709835373039823\n",
      "accuracy 0.807\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  2.513653048174774\n",
      "accuracy 0.964375\n",
      "test_loss 0.23889895764598623\n",
      "accuracy 0.777\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 63% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 23% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▄▂▁▆</td></tr><tr><td>FN_test</td><td>▁█▃▇▄</td></tr><tr><td>FP</td><td>█▃▂▁▄</td></tr><tr><td>FP_test</td><td>▂▁▂▂█</td></tr><tr><td>TN</td><td>▁▅▇█▃</td></tr><tr><td>TN_test</td><td>█▁▆▂▅</td></tr><tr><td>TP</td><td>▁▆▇█▅</td></tr><tr><td>TP_test</td><td>▇█▇▇▁</td></tr><tr><td>accuracy_test</td><td>█▆▇▆▁</td></tr><tr><td>accuracy_train</td><td>▁▆▇█▅</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>█▇▇▆▁</td></tr><tr><td>f1_train</td><td>▁▆▇█▅</td></tr><tr><td>negativePredictiveValue_test</td><td>█▁▆▂▅</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▅▇█▃</td></tr><tr><td>precision_test</td><td>▇█▇▇▁</td></tr><tr><td>precision_train</td><td>▁▆▇█▅</td></tr><tr><td>recal_test</td><td>█▁▆▂▂</td></tr><tr><td>recal_train</td><td>▁▅▇█▃</td></tr><tr><td>train_loss</td><td>█▃▂▁▅</td></tr><tr><td>val_loss</td><td>▃▁▂██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>144</td></tr><tr><td>FN_test</td><td>152</td></tr><tr><td>FP</td><td>195</td></tr><tr><td>FP_test</td><td>202</td></tr><tr><td>TN</td><td>39180</td></tr><tr><td>TN_test</td><td>4755</td></tr><tr><td>TP</td><td>8481</td></tr><tr><td>TP_test</td><td>891</td></tr><tr><td>accuracy_test</td><td>0.941</td></tr><tr><td>accuracy_train</td><td>0.99294</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.83427</td></tr><tr><td>f1_train</td><td>0.98041</td></tr><tr><td>negativePredictiveValue_test</td><td>0.96902</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99634</td></tr><tr><td>precision_test</td><td>0.81519</td></tr><tr><td>precision_train</td><td>0.97752</td></tr><tr><td>recal_test</td><td>0.85427</td></tr><tr><td>recal_train</td><td>0.9833</td></tr><tr><td>train_loss</td><td>0.02011</td></tr><tr><td>val_loss</td><td>0.2389</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sandy-sweep-8</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/a7fu20iw\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/a7fu20iw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_013715-a7fu20iw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: opx6xmyg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00015919681325003905\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77be4cde136f4904bceaea66e071778b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_020320-opx6xmyg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/opx6xmyg\" target=\"_blank\">helpful-sweep-9</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.5361959853007647\n",
      "accuracy 0.97025\n",
      "test_loss 0.281398799269814\n",
      "accuracy 0.8154761904761905\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.4734746156741494\n",
      "accuracy 0.971375\n",
      "test_loss 0.23938060226496347\n",
      "accuracy 0.810515873015873\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.4874369649764958\n",
      "accuracy 0.971\n",
      "test_loss 0.25545188101814204\n",
      "accuracy 0.8204365079365079\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.5251336178516794\n",
      "accuracy 0.97075\n",
      "test_loss 0.24373409356034936\n",
      "accuracy 0.8234126984126984\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.3819509922382167\n",
      "accuracy 0.978375\n",
      "test_loss 0.29452628661353614\n",
      "accuracy 0.816468253968254\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 96% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 18% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8858f5edfb647f2801cd2e156bd4494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▇▆▇▁</td></tr><tr><td>FN_test</td><td>▂▅▁██</td></tr><tr><td>FP</td><td>█▆▆▇▁</td></tr><tr><td>FP_test</td><td>█▅█▁▂</td></tr><tr><td>TN</td><td>▁▃▃▂█</td></tr><tr><td>TN_test</td><td>▇▄█▁▁</td></tr><tr><td>TP</td><td>▁▃▃▂█</td></tr><tr><td>TP_test</td><td>▁▄▁█▇</td></tr><tr><td>accuracy_test</td><td>▁▃▂█▅</td></tr><tr><td>accuracy_train</td><td>▁▃▃▂█</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▁▃▂█▆</td></tr><tr><td>f1_train</td><td>▁▃▃▂█</td></tr><tr><td>negativePredictiveValue_test</td><td>▇▄█▁▁</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▃▃▂█</td></tr><tr><td>precision_test</td><td>▁▄▁█▇</td></tr><tr><td>precision_train</td><td>▁▃▃▂█</td></tr><tr><td>recal_test</td><td>▇▄█▁▁</td></tr><tr><td>recal_train</td><td>▁▃▃▂█</td></tr><tr><td>train_loss</td><td>█▅▆▇▁</td></tr><tr><td>val_loss</td><td>▆▁▃▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>81</td></tr><tr><td>FN_test</td><td>146</td></tr><tr><td>FP</td><td>119</td></tr><tr><td>FP_test</td><td>140</td></tr><tr><td>TN</td><td>39243</td></tr><tr><td>TN_test</td><td>4761</td></tr><tr><td>TP</td><td>8557</td></tr><tr><td>TP_test</td><td>953</td></tr><tr><td>accuracy_test</td><td>0.95233</td></tr><tr><td>accuracy_train</td><td>0.99583</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.86953</td></tr><tr><td>f1_train</td><td>0.98845</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97025</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99794</td></tr><tr><td>precision_test</td><td>0.87191</td></tr><tr><td>precision_train</td><td>0.98628</td></tr><tr><td>recal_test</td><td>0.86715</td></tr><tr><td>recal_train</td><td>0.99062</td></tr><tr><td>train_loss</td><td>0.01222</td></tr><tr><td>val_loss</td><td>0.29453</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">helpful-sweep-9</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/opx6xmyg\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/opx6xmyg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_020320-opx6xmyg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7a4l4g9z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00016426907520330898\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7696ff7d1bbb42869fee3b268da431e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_023312-7a4l4g9z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/7a4l4g9z\" target=\"_blank\">ethereal-sweep-10</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.555452516450714\n",
      "accuracy 0.969375\n",
      "test_loss 0.21542217995646218\n",
      "accuracy 0.808531746031746\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.48316781526409613\n",
      "accuracy 0.97325\n",
      "test_loss 0.24178346455289376\n",
      "accuracy 0.8115079365079365\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.5118235068512149\n",
      "accuracy 0.9725\n",
      "test_loss 0.23900427933161458\n",
      "accuracy 0.8313492063492064\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.6383101557494228\n",
      "accuracy 0.968\n",
      "test_loss 0.23509599137607784\n",
      "accuracy 0.810515873015873\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.30595568351691327\n",
      "accuracy 0.982625\n",
      "test_loss 0.24203415559456934\n",
      "accuracy 0.8244047619047619\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 96% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 19% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e813abd8e324c288a4117af63f1d533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▇▅▆█▁</td></tr><tr><td>FN_test</td><td>▄█▁▄▂</td></tr><tr><td>FP</td><td>▇▅▆█▁</td></tr><tr><td>FP_test</td><td>█▁▇█▃</td></tr><tr><td>TN</td><td>▂▄▃▁█</td></tr><tr><td>TN_test</td><td>▅▁█▅▇</td></tr><tr><td>TP</td><td>▂▄▃▁█</td></tr><tr><td>TP_test</td><td>▁█▂▁▆</td></tr><tr><td>accuracy_test</td><td>▁▂▆▁█</td></tr><tr><td>accuracy_train</td><td>▂▄▃▁█</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▁▃▅▁█</td></tr><tr><td>f1_train</td><td>▂▄▃▁█</td></tr><tr><td>negativePredictiveValue_test</td><td>▅▁█▅▇</td></tr><tr><td>negativePredictiveValue_train</td><td>▂▄▃▁█</td></tr><tr><td>precision_test</td><td>▁█▂▁▆</td></tr><tr><td>precision_train</td><td>▂▄▃▁█</td></tr><tr><td>recal_test</td><td>▄▁█▄▇</td></tr><tr><td>recal_train</td><td>▂▄▃▁█</td></tr><tr><td>train_loss</td><td>▆▅▅█▁</td></tr><tr><td>val_loss</td><td>▁█▇▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>68</td></tr><tr><td>FN_test</td><td>131</td></tr><tr><td>FP</td><td>93</td></tr><tr><td>FP_test</td><td>141</td></tr><tr><td>TN</td><td>39256</td></tr><tr><td>TN_test</td><td>4776</td></tr><tr><td>TP</td><td>8583</td></tr><tr><td>TP_test</td><td>952</td></tr><tr><td>accuracy_test</td><td>0.95467</td></tr><tr><td>accuracy_train</td><td>0.99665</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.875</td></tr><tr><td>f1_train</td><td>0.99071</td></tr><tr><td>negativePredictiveValue_test</td><td>0.9733</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99827</td></tr><tr><td>precision_test</td><td>0.871</td></tr><tr><td>precision_train</td><td>0.98928</td></tr><tr><td>recal_test</td><td>0.87904</td></tr><tr><td>recal_train</td><td>0.99214</td></tr><tr><td>train_loss</td><td>0.00979</td></tr><tr><td>val_loss</td><td>0.24203</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-10</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/7a4l4g9z\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/7a4l4g9z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_023312-7a4l4g9z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bjf9dpxt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 5.119879891869945e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c54917b31e408793cfe9a045e31ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_030250-bjf9dpxt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/bjf9dpxt\" target=\"_blank\">feasible-sweep-11</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.1506710331418617\n",
      "accuracy 0.9915\n",
      "test_loss 0.22538404296418385\n",
      "accuracy 0.8263888888888888\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.08321517388799293\n",
      "accuracy 0.996375\n",
      "test_loss 0.22986607497838873\n",
      "accuracy 0.8313492063492064\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.07573458285867218\n",
      "accuracy 0.9975\n",
      "test_loss 0.23445078923684795\n",
      "accuracy 0.8273809523809523\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.05008021229696169\n",
      "accuracy 0.99775\n",
      "test_loss 0.2346181383274222\n",
      "accuracy 0.8234126984126984\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.040058925246171384\n",
      "accuracy 0.998125\n",
      "test_loss 0.2395299260810827\n",
      "accuracy 0.8323412698412699\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 96% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 19% |\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▃▃▁▂</td></tr><tr><td>FN_test</td><td>▃▁▄█▄</td></tr><tr><td>FP</td><td>█▃▂▂▁</td></tr><tr><td>FP_test</td><td>▇██▂▁</td></tr><tr><td>TN</td><td>▁▆▆█▇</td></tr><tr><td>TN_test</td><td>▆█▅▁▅</td></tr><tr><td>TP</td><td>▁▆▇▇█</td></tr><tr><td>TP_test</td><td>▂▁▁▇█</td></tr><tr><td>accuracy_test</td><td>▃▄▁▃█</td></tr><tr><td>accuracy_train</td><td>▁▆▇██</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▃▄▁▄█</td></tr><tr><td>f1_train</td><td>▁▆▇██</td></tr><tr><td>negativePredictiveValue_test</td><td>▆█▅▁▅</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▆▆█▇</td></tr><tr><td>precision_test</td><td>▂▁▁▇█</td></tr><tr><td>precision_train</td><td>▁▆▇▇█</td></tr><tr><td>recal_test</td><td>▆█▅▁▆</td></tr><tr><td>recal_train</td><td>▁▆▆█▇</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_loss</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>9</td></tr><tr><td>FN_test</td><td>139</td></tr><tr><td>FP</td><td>12</td></tr><tr><td>FP_test</td><td>124</td></tr><tr><td>TN</td><td>39315</td></tr><tr><td>TN_test</td><td>4768</td></tr><tr><td>TP</td><td>8664</td></tr><tr><td>TP_test</td><td>969</td></tr><tr><td>accuracy_test</td><td>0.95617</td></tr><tr><td>accuracy_train</td><td>0.99956</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.88051</td></tr><tr><td>f1_train</td><td>0.99879</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97167</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99977</td></tr><tr><td>precision_test</td><td>0.88655</td></tr><tr><td>precision_train</td><td>0.99862</td></tr><tr><td>recal_test</td><td>0.87455</td></tr><tr><td>recal_train</td><td>0.99896</td></tr><tr><td>train_loss</td><td>0.00128</td></tr><tr><td>val_loss</td><td>0.23953</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-sweep-11</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/bjf9dpxt\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/bjf9dpxt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_030250-bjf9dpxt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7djyqcp9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00019749800852858403\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c705a63a27149ba86f03e9d1d4a6290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_033235-7djyqcp9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/7djyqcp9\" target=\"_blank\">jumping-sweep-12</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  4.209677135118\n",
      "accuracy 0.943875\n",
      "test_loss 0.2215511452902574\n",
      "accuracy 0.804\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  4.487849284881349\n",
      "accuracy 0.937125\n",
      "test_loss 0.27926735897688193\n",
      "accuracy 0.787\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  4.340690393469231\n",
      "accuracy 0.94075\n",
      "test_loss 0.21181949672475459\n",
      "accuracy 0.762\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  4.034444887854079\n",
      "accuracy 0.9415\n",
      "test_loss 0.23723785815574228\n",
      "accuracy 0.76\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  3.8179065277081463\n",
      "accuracy 0.94675\n",
      "test_loss 0.30904312268737705\n",
      "accuracy 0.736\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 61% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 21% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d57a1e758244b187697be10ec35c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▅█▅▄▁</td></tr><tr><td>FN_test</td><td>▁▇█▄▇</td></tr><tr><td>FP</td><td>▃█▅▄▁</td></tr><tr><td>FP_test</td><td>▁▁▃▅█</td></tr><tr><td>TN</td><td>▄▁▄▅█</td></tr><tr><td>TN_test</td><td>█▃▁▅▃</td></tr><tr><td>TP</td><td>▆▁▄▅█</td></tr><tr><td>TP_test</td><td>██▆▄▁</td></tr><tr><td>accuracy_test</td><td>█▆▄▄▁</td></tr><tr><td>accuracy_train</td><td>▅▁▄▅█</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>█▆▅▄▁</td></tr><tr><td>f1_train</td><td>▅▁▄▅█</td></tr><tr><td>negativePredictiveValue_test</td><td>█▃▁▅▃</td></tr><tr><td>negativePredictiveValue_train</td><td>▄▁▄▅█</td></tr><tr><td>precision_test</td><td>██▆▄▁</td></tr><tr><td>precision_train</td><td>▆▁▄▅█</td></tr><tr><td>recal_test</td><td>█▃▂▄▁</td></tr><tr><td>recal_train</td><td>▄▁▄▅█</td></tr><tr><td>train_loss</td><td>▅█▆▃▁</td></tr><tr><td>val_loss</td><td>▂▆▁▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>221</td></tr><tr><td>FN_test</td><td>173</td></tr><tr><td>FP</td><td>306</td></tr><tr><td>FP_test</td><td>258</td></tr><tr><td>TN</td><td>39103</td></tr><tr><td>TN_test</td><td>4734</td></tr><tr><td>TP</td><td>8370</td></tr><tr><td>TP_test</td><td>835</td></tr><tr><td>accuracy_test</td><td>0.92817</td></tr><tr><td>accuracy_train</td><td>0.98902</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.79486</td></tr><tr><td>f1_train</td><td>0.96948</td></tr><tr><td>negativePredictiveValue_test</td><td>0.96474</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99438</td></tr><tr><td>precision_test</td><td>0.76395</td></tr><tr><td>precision_train</td><td>0.96473</td></tr><tr><td>recal_test</td><td>0.82837</td></tr><tr><td>recal_train</td><td>0.97428</td></tr><tr><td>train_loss</td><td>0.03054</td></tr><tr><td>val_loss</td><td>0.30904</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">jumping-sweep-12</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/7djyqcp9\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/7djyqcp9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_033235-7djyqcp9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rjmyj2th with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00019782989063321055\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bec920fe28b43c0af373d79603c28b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_035844-rjmyj2th</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/rjmyj2th\" target=\"_blank\">spring-sweep-13</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  3.6918176052222407\n",
      "accuracy 0.9505\n",
      "test_loss 0.2555091297025792\n",
      "accuracy 0.759\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  3.9760842676441825\n",
      "accuracy 0.942375\n",
      "test_loss 0.22451296484470368\n",
      "accuracy 0.805\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  4.0795025053539575\n",
      "accuracy 0.94125\n",
      "test_loss 0.25562992684263736\n",
      "accuracy 0.769\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  4.273785975105056\n",
      "accuracy 0.94125\n",
      "test_loss 0.21784288163913879\n",
      "accuracy 0.801\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  3.482848112380452\n",
      "accuracy 0.9475\n",
      "test_loss 0.21177715338161215\n",
      "accuracy 0.818\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 61% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 21% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95779aae9134aa6abd68d1a21ae9e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▁██▇▂</td></tr><tr><td>FN_test</td><td>█▁█▃▂</td></tr><tr><td>FP</td><td>▁▆▇█▂</td></tr><tr><td>FP_test</td><td>█▅▆▅▁</td></tr><tr><td>TN</td><td>█▁▁▂▇</td></tr><tr><td>TN_test</td><td>▁█▁▆▇</td></tr><tr><td>TP</td><td>█▃▂▁▇</td></tr><tr><td>TP_test</td><td>▁▄▃▅█</td></tr><tr><td>accuracy_test</td><td>▁▇▂▆█</td></tr><tr><td>accuracy_train</td><td>█▂▁▁▇</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▁▆▂▆█</td></tr><tr><td>f1_train</td><td>█▂▁▁▇</td></tr><tr><td>negativePredictiveValue_test</td><td>▁█▁▆▇</td></tr><tr><td>negativePredictiveValue_train</td><td>█▁▁▂▇</td></tr><tr><td>precision_test</td><td>▁▄▃▄█</td></tr><tr><td>precision_train</td><td>█▃▂▁▇</td></tr><tr><td>recal_test</td><td>▁█▁▆▇</td></tr><tr><td>recal_train</td><td>█▁▁▂▇</td></tr><tr><td>train_loss</td><td>▃▅▆█▁</td></tr><tr><td>val_loss</td><td>█▃█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>210</td></tr><tr><td>FN_test</td><td>134</td></tr><tr><td>FP</td><td>298</td></tr><tr><td>FP_test</td><td>155</td></tr><tr><td>TN</td><td>39114</td></tr><tr><td>TN_test</td><td>4773</td></tr><tr><td>TP</td><td>8378</td></tr><tr><td>TP_test</td><td>938</td></tr><tr><td>accuracy_test</td><td>0.95183</td></tr><tr><td>accuracy_train</td><td>0.98942</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.86651</td></tr><tr><td>f1_train</td><td>0.97057</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97269</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99466</td></tr><tr><td>precision_test</td><td>0.85819</td></tr><tr><td>precision_train</td><td>0.96565</td></tr><tr><td>recal_test</td><td>0.875</td></tr><tr><td>recal_train</td><td>0.97555</td></tr><tr><td>train_loss</td><td>0.02786</td></tr><tr><td>val_loss</td><td>0.21178</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-sweep-13</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/rjmyj2th\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/rjmyj2th</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_035844-rjmyj2th\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hgkf91ww with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00011835086327239576\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e16a5814a514e07909324b2c208e8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_042456-hgkf91ww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/hgkf91ww\" target=\"_blank\">classic-sweep-14</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.4450020202239102\n",
      "accuracy 0.975875\n",
      "test_loss 0.2432614902019619\n",
      "accuracy 0.814484126984127\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.20255759530482464\n",
      "accuracy 0.989625\n",
      "test_loss 0.24854480614885688\n",
      "accuracy 0.8214285714285714\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.14305465333904976\n",
      "accuracy 0.993\n",
      "test_loss 0.25491407689534956\n",
      "accuracy 0.8253968253968254\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.11024931677775385\n",
      "accuracy 0.9945\n",
      "test_loss 0.2608208452029863\n",
      "accuracy 0.8293650793650794\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.19709085128283732\n",
      "accuracy 0.989\n",
      "test_loss 0.2955194623579109\n",
      "accuracy 0.7886904761904762\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 97% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 19% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db408d982784afba340dea82230bdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▂▁▁▃</td></tr><tr><td>FN_test</td><td>▁▅▄▄█</td></tr><tr><td>FP</td><td>█▃▂▁▃</td></tr><tr><td>FP_test</td><td>█▃▂▁▇</td></tr><tr><td>TN</td><td>▁▇██▆</td></tr><tr><td>TN_test</td><td>█▄▅▅▁</td></tr><tr><td>TP</td><td>▁▆▇█▆</td></tr><tr><td>TP_test</td><td>▁▆▇█▂</td></tr><tr><td>accuracy_test</td><td>▅▅▇█▁</td></tr><tr><td>accuracy_train</td><td>▁▆▇█▆</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▄▅▇█▁</td></tr><tr><td>f1_train</td><td>▁▆▇█▆</td></tr><tr><td>negativePredictiveValue_test</td><td>█▄▅▅▁</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▇██▆</td></tr><tr><td>precision_test</td><td>▁▆▇█▂</td></tr><tr><td>precision_train</td><td>▁▆▇█▆</td></tr><tr><td>recal_test</td><td>█▄▅▆▁</td></tr><tr><td>recal_train</td><td>▁▇██▆</td></tr><tr><td>train_loss</td><td>█▃▂▁▃</td></tr><tr><td>val_loss</td><td>▁▂▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>43</td></tr><tr><td>FN_test</td><td>155</td></tr><tr><td>FP</td><td>58</td></tr><tr><td>FP_test</td><td>174</td></tr><tr><td>TN</td><td>39281</td></tr><tr><td>TN_test</td><td>4752</td></tr><tr><td>TP</td><td>8618</td></tr><tr><td>TP_test</td><td>919</td></tr><tr><td>accuracy_test</td><td>0.94517</td></tr><tr><td>accuracy_train</td><td>0.9979</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.84818</td></tr><tr><td>f1_train</td><td>0.99417</td></tr><tr><td>negativePredictiveValue_test</td><td>0.96841</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99891</td></tr><tr><td>precision_test</td><td>0.84081</td></tr><tr><td>precision_train</td><td>0.99331</td></tr><tr><td>recal_test</td><td>0.85568</td></tr><tr><td>recal_train</td><td>0.99504</td></tr><tr><td>train_loss</td><td>0.00631</td></tr><tr><td>val_loss</td><td>0.29552</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">classic-sweep-14</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/hgkf91ww\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/hgkf91ww</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_042456-hgkf91ww\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v6kdmln9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00014439380304690543\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_045447-v6kdmln9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/v6kdmln9\" target=\"_blank\">whole-sweep-15</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  1.2895930422457695\n",
      "accuracy 0.982125\n",
      "test_loss 0.2459617384544108\n",
      "accuracy 0.827\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  2.6370534244122155\n",
      "accuracy 0.964\n",
      "test_loss 0.21937238524202257\n",
      "accuracy 0.8\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  2.208967310317803\n",
      "accuracy 0.969875\n",
      "test_loss 0.2419292888509226\n",
      "accuracy 0.799\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  2.3721670049466184\n",
      "accuracy 0.966\n",
      "test_loss 0.2244101593765663\n",
      "accuracy 0.803\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  1.2499745897853245\n",
      "accuracy 0.981\n",
      "test_loss 0.25588881727634\n",
      "accuracy 0.811\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 60% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 21% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▁█▅▇▂</td></tr><tr><td>FN_test</td><td>▁█▅▄▁</td></tr><tr><td>FP</td><td>▁█▇█▂</td></tr><tr><td>FP_test</td><td>▃▁█▆▆</td></tr><tr><td>TN</td><td>█▁▄▂▇</td></tr><tr><td>TN_test</td><td>█▁▅▅█</td></tr><tr><td>TP</td><td>█▁▂▁▇</td></tr><tr><td>TP_test</td><td>▆█▁▃▃</td></tr><tr><td>accuracy_test</td><td>█▅▁▃▆</td></tr><tr><td>accuracy_train</td><td>█▁▃▂▇</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>█▆▁▃▆</td></tr><tr><td>f1_train</td><td>█▁▃▂▇</td></tr><tr><td>negativePredictiveValue_test</td><td>█▁▅▅█</td></tr><tr><td>negativePredictiveValue_train</td><td>█▁▄▂▇</td></tr><tr><td>precision_test</td><td>▆█▁▃▃</td></tr><tr><td>precision_train</td><td>█▁▂▁▇</td></tr><tr><td>recal_test</td><td>█▁▃▄▇</td></tr><tr><td>recal_train</td><td>█▁▃▂▇</td></tr><tr><td>train_loss</td><td>▁█▆▇▁</td></tr><tr><td>val_loss</td><td>▆▁▅▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>71</td></tr><tr><td>FN_test</td><td>128</td></tr><tr><td>FP</td><td>105</td></tr><tr><td>FP_test</td><td>166</td></tr><tr><td>TN</td><td>39253</td></tr><tr><td>TN_test</td><td>4779</td></tr><tr><td>TP</td><td>8571</td></tr><tr><td>TP_test</td><td>927</td></tr><tr><td>accuracy_test</td><td>0.951</td></tr><tr><td>accuracy_train</td><td>0.99633</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.86313</td></tr><tr><td>f1_train</td><td>0.98984</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97391</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99819</td></tr><tr><td>precision_test</td><td>0.84812</td></tr><tr><td>precision_train</td><td>0.9879</td></tr><tr><td>recal_test</td><td>0.87867</td></tr><tr><td>recal_train</td><td>0.99178</td></tr><tr><td>train_loss</td><td>0.01</td></tr><tr><td>val_loss</td><td>0.25589</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">whole-sweep-15</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/v6kdmln9\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/v6kdmln9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_045447-v6kdmln9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 41hfh2uy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 7.237567667076324e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13da009ba994471ba8ade6cdacd66b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_052058-41hfh2uy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/41hfh2uy\" target=\"_blank\">honest-sweep-16</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.17265069971676894\n",
      "accuracy 0.99175\n",
      "test_loss 0.2557796732409828\n",
      "accuracy 0.816468253968254\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.08356209392331948\n",
      "accuracy 0.99625\n",
      "test_loss 0.27778257436159676\n",
      "accuracy 0.8204365079365079\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.05131643364188676\n",
      "accuracy 0.99775\n",
      "test_loss 0.25991242107452955\n",
      "accuracy 0.8234126984126984\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.039862189028212924\n",
      "accuracy 0.998\n",
      "test_loss 0.26597205833402565\n",
      "accuracy 0.8283730158730159\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.03332246968966501\n",
      "accuracy 0.99825\n",
      "test_loss 0.26545654225074466\n",
      "accuracy 0.8303571428571429\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 97% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 19% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▃▂▂▁</td></tr><tr><td>FN_test</td><td>█▅▁▆▃</td></tr><tr><td>FP</td><td>█▃▂▁▁</td></tr><tr><td>FP_test</td><td>▃█▅▁▂</td></tr><tr><td>TN</td><td>▁▆▇▇█</td></tr><tr><td>TN_test</td><td>▁▄█▃▆</td></tr><tr><td>TP</td><td>▁▆▇██</td></tr><tr><td>TP_test</td><td>▆▁▄█▇</td></tr><tr><td>accuracy_test</td><td>▂▁█▆█</td></tr><tr><td>accuracy_train</td><td>▁▆▇██</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▃▁▇▆█</td></tr><tr><td>f1_train</td><td>▁▆▇██</td></tr><tr><td>negativePredictiveValue_test</td><td>▁▄█▃▆</td></tr><tr><td>negativePredictiveValue_train</td><td>▁▆▇▇█</td></tr><tr><td>precision_test</td><td>▆▁▄█▇</td></tr><tr><td>precision_train</td><td>▁▆▇██</td></tr><tr><td>recal_test</td><td>▁▄█▃▆</td></tr><tr><td>recal_train</td><td>▁▆▇▇█</td></tr><tr><td>train_loss</td><td>█▄▂▁▁</td></tr><tr><td>val_loss</td><td>▁█▂▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>9</td></tr><tr><td>FN_test</td><td>141</td></tr><tr><td>FP</td><td>12</td></tr><tr><td>FP_test</td><td>135</td></tr><tr><td>TN</td><td>39315</td></tr><tr><td>TN_test</td><td>4766</td></tr><tr><td>TP</td><td>8664</td></tr><tr><td>TP_test</td><td>958</td></tr><tr><td>accuracy_test</td><td>0.954</td></tr><tr><td>accuracy_train</td><td>0.99956</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.87409</td></tr><tr><td>f1_train</td><td>0.99879</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97127</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99977</td></tr><tr><td>precision_test</td><td>0.87649</td></tr><tr><td>precision_train</td><td>0.99862</td></tr><tr><td>recal_test</td><td>0.8717</td></tr><tr><td>recal_train</td><td>0.99896</td></tr><tr><td>train_loss</td><td>0.00107</td></tr><tr><td>val_loss</td><td>0.26546</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">honest-sweep-16</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/41hfh2uy\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/41hfh2uy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_052058-41hfh2uy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fr8gscci with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 4.449682547502634e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae30debf36a44f979bad66639b41f81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_054709-fr8gscci</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/fr8gscci\" target=\"_blank\">genial-sweep-17</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.03910769687092852\n",
      "accuracy 0.998\n",
      "test_loss 0.2632966344688265\n",
      "accuracy 0.8283730158730159\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.03376381296459385\n",
      "accuracy 0.9985\n",
      "test_loss 0.27151699076657965\n",
      "accuracy 0.8234126984126984\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.029826790186689323\n",
      "accuracy 0.99825\n",
      "test_loss 0.27559953880318927\n",
      "accuracy 0.8253968253968254\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.10828133491190783\n",
      "accuracy 0.993875\n",
      "test_loss 0.2600040317629464\n",
      "accuracy 0.8174603174603174\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.08090682643160108\n",
      "accuracy 0.99525\n",
      "test_loss 0.25686578109208125\n",
      "accuracy 0.8224206349206349\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 96% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 18% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▁▁▁█▃</td></tr><tr><td>FN_test</td><td>▁█▇▅▆</td></tr><tr><td>FP</td><td>▂▁▁█▇</td></tr><tr><td>FP_test</td><td>█▆▅█▁</td></tr><tr><td>TN</td><td>███▁▆</td></tr><tr><td>TN_test</td><td>█▁▂▅▃</td></tr><tr><td>TP</td><td>▇██▁▂</td></tr><tr><td>TP_test</td><td>▁▃▅▁█</td></tr><tr><td>accuracy_test</td><td>█▁▄▄▇</td></tr><tr><td>accuracy_train</td><td>▇██▁▃</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▇▁▄▃█</td></tr><tr><td>f1_train</td><td>▇██▁▃</td></tr><tr><td>negativePredictiveValue_test</td><td>█▁▂▅▃</td></tr><tr><td>negativePredictiveValue_train</td><td>███▁▆</td></tr><tr><td>precision_test</td><td>▁▃▅▁█</td></tr><tr><td>precision_train</td><td>▇██▁▂</td></tr><tr><td>recal_test</td><td>█▁▃▄▄</td></tr><tr><td>recal_train</td><td>███▁▆</td></tr><tr><td>train_loss</td><td>▂▁▁█▆</td></tr><tr><td>val_loss</td><td>▃▆█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>15</td></tr><tr><td>FN_test</td><td>145</td></tr><tr><td>FP</td><td>28</td></tr><tr><td>FP_test</td><td>133</td></tr><tr><td>TN</td><td>39309</td></tr><tr><td>TN_test</td><td>4762</td></tr><tr><td>TP</td><td>8648</td></tr><tr><td>TP_test</td><td>960</td></tr><tr><td>accuracy_test</td><td>0.95367</td></tr><tr><td>accuracy_train</td><td>0.9991</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.87352</td></tr><tr><td>f1_train</td><td>0.99752</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97045</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99962</td></tr><tr><td>precision_test</td><td>0.87832</td></tr><tr><td>precision_train</td><td>0.99677</td></tr><tr><td>recal_test</td><td>0.86878</td></tr><tr><td>recal_train</td><td>0.99827</td></tr><tr><td>train_loss</td><td>0.00259</td></tr><tr><td>val_loss</td><td>0.25687</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">genial-sweep-17</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/fr8gscci\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/fr8gscci</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_054709-fr8gscci\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9oko9kwb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 8.327577359973492e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_061448-9oko9kwb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/9oko9kwb\" target=\"_blank\">rare-sweep-18</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.6160027589087917\n",
      "accuracy 0.991875\n",
      "test_loss 0.2702674101882149\n",
      "accuracy 0.785\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  1.0666502667577333\n",
      "accuracy 0.98575\n",
      "test_loss 0.24850875867303693\n",
      "accuracy 0.806\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.5671411030328386\n",
      "accuracy 0.9925\n",
      "test_loss 0.2551903794764657\n",
      "accuracy 0.82\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.35848136277377307\n",
      "accuracy 0.994625\n",
      "test_loss 0.2730361157776788\n",
      "accuracy 0.816\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  1.0292570735113031\n",
      "accuracy 0.984\n",
      "test_loss 0.27464836134260984\n",
      "accuracy 0.8\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 60% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 21% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1159998141489c83215b1d66cd90b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▃█▂▁█</td></tr><tr><td>FN_test</td><td>▅▅▁▂█</td></tr><tr><td>FP</td><td>▃▇▃▁█</td></tr><tr><td>FP_test</td><td>█▃▁▄▁</td></tr><tr><td>TN</td><td>▆▁▇█▁</td></tr><tr><td>TN_test</td><td>▄▄█▇▁</td></tr><tr><td>TP</td><td>▆▂▆█▁</td></tr><tr><td>TP_test</td><td>▁▆█▅█</td></tr><tr><td>accuracy_test</td><td>▁▄█▆▃</td></tr><tr><td>accuracy_train</td><td>▆▂▆█▁</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▁▄█▆▄</td></tr><tr><td>f1_train</td><td>▆▂▆█▁</td></tr><tr><td>negativePredictiveValue_test</td><td>▄▄█▇▁</td></tr><tr><td>negativePredictiveValue_train</td><td>▆▁▇█▁</td></tr><tr><td>precision_test</td><td>▁▆█▅█</td></tr><tr><td>precision_train</td><td>▆▂▆█▁</td></tr><tr><td>recal_test</td><td>▃▄█▇▁</td></tr><tr><td>recal_train</td><td>▆▁▇█▁</td></tr><tr><td>train_loss</td><td>▄█▃▁█</td></tr><tr><td>val_loss</td><td>▇▁▃██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>60</td></tr><tr><td>FN_test</td><td>173</td></tr><tr><td>FP</td><td>82</td></tr><tr><td>FP_test</td><td>150</td></tr><tr><td>TN</td><td>39264</td></tr><tr><td>TN_test</td><td>4734</td></tr><tr><td>TP</td><td>8594</td></tr><tr><td>TP_test</td><td>943</td></tr><tr><td>accuracy_test</td><td>0.94617</td></tr><tr><td>accuracy_train</td><td>0.99704</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.85378</td></tr><tr><td>f1_train</td><td>0.99181</td></tr><tr><td>negativePredictiveValue_test</td><td>0.96474</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99847</td></tr><tr><td>precision_test</td><td>0.86276</td></tr><tr><td>precision_train</td><td>0.99055</td></tr><tr><td>recal_test</td><td>0.84498</td></tr><tr><td>recal_train</td><td>0.99307</td></tr><tr><td>train_loss</td><td>0.00823</td></tr><tr><td>val_loss</td><td>0.27465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rare-sweep-18</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/9oko9kwb\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/9oko9kwb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_061448-9oko9kwb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ctqindvd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 5.414521436862289e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfece60b4029400d80dabc4d7daa3148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666414434, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_064104-ctqindvd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/ctqindvd\" target=\"_blank\">major-sweep-19</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.11283928746956917\n",
      "accuracy 0.995\n",
      "test_loss 0.2906663745392189\n",
      "accuracy 0.814484126984127\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.034431256474420024\n",
      "accuracy 0.99825\n",
      "test_loss 0.27057993815902764\n",
      "accuracy 0.8234126984126984\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.024546396107325563\n",
      "accuracy 0.9985\n",
      "test_loss 0.2677825259061859\n",
      "accuracy 0.8303571428571429\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.02290957211641853\n",
      "accuracy 0.99825\n",
      "test_loss 0.2679916706720611\n",
      "accuracy 0.8283730158730159\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.023161964313317185\n",
      "accuracy 0.998375\n",
      "test_loss 0.26799055907308467\n",
      "accuracy 0.8194444444444444\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 97% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 19% |\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>█▁▁▁▁</td></tr><tr><td>FN_test</td><td>█▁▁▃▃</td></tr><tr><td>FP</td><td>█▁▁▁▁</td></tr><tr><td>FP_test</td><td>█▆▄▁▇</td></tr><tr><td>TN</td><td>▁████</td></tr><tr><td>TN_test</td><td>▁██▆▆</td></tr><tr><td>TP</td><td>▁████</td></tr><tr><td>TP_test</td><td>▁▃▅█▂</td></tr><tr><td>accuracy_test</td><td>▁▇█▇▅</td></tr><tr><td>accuracy_train</td><td>▁████</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▁▇█▇▅</td></tr><tr><td>f1_train</td><td>▁████</td></tr><tr><td>negativePredictiveValue_test</td><td>▁██▆▆</td></tr><tr><td>negativePredictiveValue_train</td><td>▁████</td></tr><tr><td>precision_test</td><td>▁▃▅█▂</td></tr><tr><td>precision_train</td><td>▁████</td></tr><tr><td>recal_test</td><td>▁▇█▆▆</td></tr><tr><td>recal_train</td><td>▁████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>8</td></tr><tr><td>FN_test</td><td>142</td></tr><tr><td>FP</td><td>10</td></tr><tr><td>FP_test</td><td>133</td></tr><tr><td>TN</td><td>39316</td></tr><tr><td>TN_test</td><td>4765</td></tr><tr><td>TP</td><td>8666</td></tr><tr><td>TP_test</td><td>960</td></tr><tr><td>accuracy_test</td><td>0.95417</td></tr><tr><td>accuracy_train</td><td>0.99962</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.87472</td></tr><tr><td>f1_train</td><td>0.99896</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97106</td></tr><tr><td>negativePredictiveValue_train</td><td>0.9998</td></tr><tr><td>precision_test</td><td>0.87832</td></tr><tr><td>precision_train</td><td>0.99885</td></tr><tr><td>recal_test</td><td>0.87114</td></tr><tr><td>recal_train</td><td>0.99908</td></tr><tr><td>train_loss</td><td>0.00074</td></tr><tr><td>val_loss</td><td>0.26799</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">major-sweep-19</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/ctqindvd\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/ctqindvd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_064104-ctqindvd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3usa5pu3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00011130066903909835\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e5c4d3e782406a8418669cbaf623d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Thesis\\Model train\\Prepare\\wandb\\run-20221201_070926-3usa5pu3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/3usa5pu3\" target=\"_blank\">distinctive-sweep-20</a></strong> to <a href=\"https://wandb.ai/makkuror/modeltunning_16\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/sweeps/0metq8be</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Epoch  0\n",
      "Client ID  , epoch  0 :  0.1754891948619388\n",
      "accuracy 0.989375\n",
      "test_loss 0.2654038741445494\n",
      "accuracy 0.8263888888888888\n",
      "start Epoch  1\n",
      "Client ID  , epoch  1 :  0.15630500825591298\n",
      "accuracy 0.99125\n",
      "test_loss 0.28349131637064384\n",
      "accuracy 0.8323412698412699\n",
      "start Epoch  2\n",
      "Client ID  , epoch  2 :  0.21439601841277067\n",
      "accuracy 0.987375\n",
      "test_loss 0.31982895293021146\n",
      "accuracy 0.8174603174603174\n",
      "start Epoch  3\n",
      "Client ID  , epoch  3 :  0.3118997976787341\n",
      "accuracy 0.983125\n",
      "test_loss 0.2706742842519094\n",
      "accuracy 0.7946428571428571\n",
      "start Epoch  4\n",
      "Client ID  , epoch  4 :  0.20141826874714752\n",
      "accuracy 0.98875\n",
      "test_loss 0.27285825541900793\n",
      "accuracy 0.814484126984127\n",
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 97% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 19% |\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Tensor: GPU pinned 32 × 3 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 16 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 16\n",
      "Tensor: GPU pinned 96 × 16 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 24 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 24 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 24\n",
      "Tensor: GPU pinned 144 × 24 × 1 × 1\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 144\n",
      "Tensor: GPU pinned 32 × 144 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 32 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 32\n",
      "Tensor: GPU pinned 192 × 32 × 1 × 1\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 192\n",
      "Tensor: GPU pinned 64 × 192 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 64 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 64\n",
      "Tensor: GPU pinned 384 × 64 × 1 × 1\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 384\n",
      "Tensor: GPU pinned 96 × 384 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 96 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 96\n",
      "Tensor: GPU pinned 576 × 96 × 1 × 1\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 576\n",
      "Tensor: GPU pinned 160 × 576 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 160 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 160\n",
      "Tensor: GPU pinned 960 × 160 × 1 × 1\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960 × 1 × 3 × 3\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 960\n",
      "Tensor: GPU pinned 320 × 960 × 1 × 1\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 320\n",
      "Tensor: GPU pinned 1280 × 320 × 1 × 1\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 1280\n",
      "Tensor: GPU pinned 6 × 1280\n",
      "Tensor: GPU pinned 6\n",
      "Total size: 4463116\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>▂▁▃█▃</td></tr><tr><td>FN_test</td><td>▂▁▂█▅</td></tr><tr><td>FP</td><td>▃▁▄█▃</td></tr><tr><td>FP_test</td><td>▁▁█▇▃</td></tr><tr><td>TN</td><td>▇█▆▁▆</td></tr><tr><td>TN_test</td><td>▇█▇▁▄</td></tr><tr><td>TP</td><td>▆█▅▁▆</td></tr><tr><td>TP_test</td><td>██▁▂▆</td></tr><tr><td>accuracy_test</td><td>▇█▆▁▄</td></tr><tr><td>accuracy_train</td><td>▇█▅▁▆</td></tr><tr><td>epoc</td><td>▁▃▅▆█</td></tr><tr><td>f1_test</td><td>▇█▅▁▄</td></tr><tr><td>f1_train</td><td>▇█▅▁▆</td></tr><tr><td>negativePredictiveValue_test</td><td>▇█▇▁▄</td></tr><tr><td>negativePredictiveValue_train</td><td>▇█▆▁▆</td></tr><tr><td>precision_test</td><td>██▁▂▆</td></tr><tr><td>precision_train</td><td>▆█▅▁▆</td></tr><tr><td>recal_test</td><td>▇█▆▁▄</td></tr><tr><td>recal_train</td><td>▇█▆▁▆</td></tr><tr><td>train_loss</td><td>▂▁▄█▃</td></tr><tr><td>val_loss</td><td>▁▃█▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>FN</td><td>49</td></tr><tr><td>FN_test</td><td>142</td></tr><tr><td>FP</td><td>58</td></tr><tr><td>FP_test</td><td>162</td></tr><tr><td>TN</td><td>39275</td></tr><tr><td>TN_test</td><td>4765</td></tr><tr><td>TP</td><td>8618</td></tr><tr><td>TP_test</td><td>931</td></tr><tr><td>accuracy_test</td><td>0.94933</td></tr><tr><td>accuracy_train</td><td>0.99777</td></tr><tr><td>epoc</td><td>4</td></tr><tr><td>f1_test</td><td>0.85965</td></tr><tr><td>f1_train</td><td>0.99383</td></tr><tr><td>negativePredictiveValue_test</td><td>0.97106</td></tr><tr><td>negativePredictiveValue_train</td><td>0.99875</td></tr><tr><td>precision_test</td><td>0.85178</td></tr><tr><td>precision_train</td><td>0.99331</td></tr><tr><td>recal_test</td><td>0.86766</td></tr><tr><td>recal_train</td><td>0.99435</td></tr><tr><td>train_loss</td><td>0.00645</td></tr><tr><td>val_loss</td><td>0.27286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">distinctive-sweep-20</strong>: <a href=\"https://wandb.ai/makkuror/modeltunning_16/runs/3usa5pu3\" target=\"_blank\">https://wandb.ai/makkuror/modeltunning_16/runs/3usa5pu3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221201_070926-3usa5pu3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = '831281456cbf2d04f75207adc2e9811dc4fd32cf'\n",
    "def main():\n",
    "    dump_tensors()\n",
    "\n",
    "    run = wandb.init()\n",
    "    \n",
    "    # note that we define values from `wandb.config` instead \n",
    "    # of defining hard values\n",
    "\n",
    "    config = {\n",
    "        \"lr\": wandb.config.lr,\n",
    "        \"batch_size\":wandb.config.batch_size,\n",
    "        \"epoch\":wandb.config.epochs\n",
    "    }\n",
    "    import warnings \n",
    "    warnings.filterwarnings('ignore')\n",
    "    a=client_trainGPU(config)\n",
    "\n",
    "\n",
    "\n",
    "# Start sweep job.\n",
    "wandb.agent(sweep_id, function=main, count=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear Memory GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 0\n"
     ]
    }
   ],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)\n",
    "dump_tensors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Thesis\\Model train\\Prepare\\ModelTunning.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Prepare/ModelTunning.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,target\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Prepare/ModelTunning.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m        \u001b[39mprint\u001b[39m(accuracy_score(target[i], pred[i]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Thesis/Model%20train/Prepare/ModelTunning.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m f1_score(a,b)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "cf_matrix=0\n",
    "\n",
    "def confusion_matrix(target,pred):\n",
    "    for i in range(0,target.shape[0]):\n",
    "        cf_matrix+=confusion_matrix(target[i], pred[i])\n",
    "def f1_score(target,pred):\n",
    "    for i in range(0,target.shape[0]):\n",
    "       print(accuracy_score(target[i], pred[i]))\n",
    "f1_score(a,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorchGPUI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8b858f47e475f096c0bf0df9132e4b2b12ebb02cb87303e1af43904bc641e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
